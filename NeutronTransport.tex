\documentclass[10pt]{article}
\usepackage[letterpaper]{geometry}
\geometry{verbose,tmargin=1in,bmargin=1in,lmargin=1in,rmargin=1in}
\usepackage{setspace}
\usepackage{ragged2e}
\usepackage{color}
\usepackage{titlesec}
\usepackage{graphicx}
\usepackage{float}
\usepackage{mathtools}
\usepackage{amsmath}
\usepackage[font=small,labelfont=bf,labelsep=period]{caption}
\usepackage[english]{babel}
\usepackage{indentfirst}
\usepackage{array}
\usepackage{makecell}
\usepackage[usenames,dvipsnames]{xcolor}
\usepackage{multirow}
\usepackage{tabularx}
\usepackage{arydshln}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{xfrac}
\usepackage{etoolbox}
\usepackage{cite}
\usepackage{url}
\usepackage{dcolumn}
\usepackage{hyperref}
\usepackage{courier}
\usepackage{url}
\usepackage{esvect}
\usepackage{commath}
\usepackage{verbatim} % for block comments
\usepackage{enumitem}
\usepackage{hyperref} % for clickable table of contents
\usepackage{braket}
\usepackage{titlesec}
\usepackage{booktabs}
\usepackage{gensymb}
\usepackage{longtable}
\usepackage{soul} % for striking out text
\usepackage{tcolorbox} % for colored boxes
\tcbuselibrary{breakable} % to allow colored boxed to extend over multiple pages
\usepackage[makeroom]{cancel}	% to cancel out text
\usepackage{breqn}
\usepackage[mathscr]{euscript}
\usepackage[acronym,nomain,nonumberlist,nogroupskip,nopostdot]{glossaries} % for glossary of acronyms

% for circled numbers
\usepackage{tikz}
\newcommand*\circled[1]{\tikz[baseline=(char.base)]{
            \node[shape=circle,draw,inner sep=2pt] (char) {#1};}}

\newcommand{\beq}{\begin{equation}}
\newcommand{\eeq}{\end{equation}}
\newcommand{\beqa}{\begin{equation}\begin{aligned}}
\newcommand{\eeqa}{\end{aligned}\end{equation}}
\newcommand{\hO}{\hat{\Omega}}
\newcommand{\Om}{\Omega}
\newcommand{\spa}{(\vv{r}, E, \hO, t)}
\newcommand{\seat}{(\vv{r}, E, \hO, t)}
\newcommand{\seatelse}{(\vv{r},E',\hO',t)}
\newcommand{\sat}{(\vv{r},\hO,t)}
\newcommand{\sset}{(\vv{r},E,t)}
\newcommand{\seatprime}{(\vv{r},E',\hO',t)}
\newcommand{\seatout}{(\vv{r},E'\rightarrow E,\hO'\rightarrow \hO,t)}
\newcommand{\spas}{(\vv{r},E,t)}
\newcommand{\spap}{(\vv{r}, E', \hO',t)}
\newcommand{\spaps}{(\vv{r},E',t)}
\newcommand{\spang}{(\vv{r},E'\rightarrow E, \hO'\rightarrow\hO,t)}
\newcommand{\spangr}{(\vv{r},E\rightarrow E', \hO\rightarrow\hO',t)}
\newcommand{\dEprime}{\int_{0}^\infty dE'}
\newcommand{\dhOprime}{\int_{4\pi}d\hO'}

% integrand (minus the flux) of the prompt fission source
\newcommand{\promptfissionsource}{\chi_p(E,\hO)\dEprime\dhOprime\left\lbrack1-\beta(E')\right\rbrack\nu(E')\Sigma_f\seatprime}

% summation form of the delayed neutron source
\newcommand{\delayedfissionsource}{\sum_{j=1}^J\chi_{d,j}(E,\hO)\lambda_jC_j(\vv{r},t)}

% total fission source
\newcommand{\totalfissionsource}{\chi(E,\hO)\int_0^\infty dE'\int_{4\pi}d\hO' \nu(E')\Sigma_f\seatprime}

% in-scattering source
\newcommand{\inscatteringsource}{\int_0^\infty dE'\int_{4\pi}d\hO'\Sigma_s\seatout}

% external source
\newcommand{\source}{S\seat}

\titleclass{\subsubsubsection}{straight}[\subsection]

% define new command for triple sub sections
\newcounter{subsubsubsection}[subsubsection]
\renewcommand\thesubsubsubsection{\thesubsubsection.\arabic{subsubsubsection}}
\renewcommand\theparagraph{\thesubsubsubsection.\arabic{paragraph}} % optional; useful if paragraphs are to be numbered

\titleformat{\subsubsubsection}
  {\normalfont\normalsize\bfseries}{\thesubsubsubsection}{1em}{}
\titlespacing*{\subsubsubsection}
{0pt}{3.25ex plus 1ex minus .2ex}{1.5ex plus .2ex}

\makeatletter
\renewcommand\paragraph{\@startsection{paragraph}{5}{\z@}%
  {3.25ex \@plus1ex \@minus.2ex}%
  {-1em}%
  {\normalfont\normalsize\bfseries}}
\renewcommand\subparagraph{\@startsection{subparagraph}{6}{\parindent}%
  {3.25ex \@plus1ex \@minus .2ex}%
  {-1em}%
  {\normalfont\normalsize\bfseries}}
\def\toclevel@subsubsubsection{4}
\def\toclevel@paragraph{5}
\def\toclevel@paragraph{6}
\def\l@subsubsubsection{\@dottedtocline{4}{7em}{4em}}
\def\l@paragraph{\@dottedtocline{5}{10em}{5em}}
\def\l@subparagraph{\@dottedtocline{6}{14em}{6em}}
\makeatother

\newcommand{\volume}{\mathop{\ooalign{\hfil$V$\hfil\cr\kern0.08em--\hfil\cr}}\nolimits}

\setcounter{secnumdepth}{4}
\setcounter{tocdepth}{4}

\setacronymstyle{long-short}
\loadglsentries{../../projects/pronghorn/doc/manual/manual_glossary}
\makeglossaries

\begin{document}

\begin{centering}
\textbf{\Large Neutron Transport}\\
\end{centering}

\tableofcontents
\clearpage

\section{Introduction}
\begin{flushleft}\justify

This document will cover the two main models for neutron populations, beginning with transport theory, and then moving to a simplification known as diffusion theory. While diffusion theory is a very accurate approximation to heat conduction or gaseous diffusion where ``random-walk'' physical processes occur frequently, it is less accurate for describing neutron populations. Due to the uncharged nature of neutrons and their sometimes fairly low interaction probabilities with the material in which they are traveling, neutrons can travel long distances without any interaction, which degrades a ``random-walk'' assumption. The interaction of a neutron population with a domain is governed by interaction probabilities. Naturally, these probabilities are functions of neutron energy, space (if the domain is heterogeneous), and time (if the domain is time-dependent). In addition, because neutrons are particles, their direction of travel also has an impact on their likelihood to undergo certain interactions in heterogeneous geometries. A neutron may be very close to a highly interacting region, but if the neutron is not moving towards that region, its probability of interaction will be entirely different. So, for heterogeneous media, the breakdown in diffusion theory is most apparent near boundaries in the geometry where there are moderate to large changes in interaction probabilities within a few mean free paths. 

So, while diffusion theory represents a much simpler model of neutron populations, it is necessary to begin with a study neutron transport. The neutron transport equation is difficult to solve due to the high dimensionality of phase space and the integro-differential form of the equation. The neutron transport equation is the linear version of the general Boltzmann transport equation developed to describe gases. Despite this great reduction in complexity from the Boltzmann equation, the solution can only be obtained in the simplest of geometries. Initially, the people who worked with the Bolztmann transport equation were satisfied by only applying it in semi-infinite media, since it was used for atmospheric and stellar applications. Its application to more finite domains really began with the field of nuclear engineering. 

\clearpage
\input{cross-sections.tex}

\clearpage
\section{Important Definitions and Identities}

This section provides important definitions that are used throughout the remainder of this document. All quantities in this section are fundamental to the understanding of the material, which is why for convenience they are all grouped together here to serve as a reference that should allow the student to reduce the amount of time needed searching for previously discussed formulas and definitions.

\subsection{General Math Definitions}
This section presents basic math definitions and syntax used.

\subsubsection{Inner Products}

An inner product is an integral over all of phase space of two quantities. For instance, the inner product of \(x\) and \(y\) over a volume \(\volume\) is, in inner product notation:

\beq
\label{eq:innerproduct}
< x, y > = \int d\volume xy
\eeq

\subsection{Quantities in the Transport Equation}
This section defines the variables that appear in the neutron transport equation.

\subsubsection{Unit Direction Vector \(\hO  \)}

In Cartesian coordinates, a neutron moves along constant \(\hO\) until suffering a collision. This is {\it not} the case in curvilinear (cylindrical, spherical, or other) coordinates, however. In curvilinear coordinates, as a neutron streams, the angular coordinates are constantly changing. If this is not intuitive, think of a neutron traveling in a 2-D Cartesian coordinate system along the line \(x = 1\). This neutron moves along constant \(\hO\). However, the same neutron, described in a cylindrical system, is constantly changing its angle relative to the \(x\)-axis. This means that \(\hO\), in the cylindrical coordinate frame, also changes as the neutron moves, even if it hasn't collided with anything!

\subsubsection{Current}

The angular current density has the same magnitude as the angular flux, except that it has direction - it denotes the current of neutrons moving in a certain angular direction \(\hO\):

\beq
\label{eq:AngularCurrent}
\vv{j}\spa = \psi\spa\hO  
\eeq

The current \(\vv{J}\) is the zeroth angular momentum of the angular current, which is equivalent to the first angular moment of the angular flux, and is given by:



The fundamental difference between current and flux is that current represents the net rate at which particles stream through a surface (since it is a vector), while flux represents the total rate at which particles stream through a surface, regardless of direction. While Eq. \ref{eq:Current} holds for the angular variables, there is no analogous, exact, relationship between \(J\), the scalar current, and \(\phi\). To determine how many neutrons cross a unit area, we must integrate the angular current over that area, dotted with the unit normal vector of that surface to indicate that only neutrons moving perpendicular to the surface actually cross it:

\beq
\label{eq:AngularCurrent}
\textrm{Surface Current} = \int dA \int_{4\pi}^{}\hO\vv{j}\spa \cdot\hat{n}
\eeq

Eq. \ref{eq:AngularCurrent} would then also be integrated over angle and energy to give the total number of neutrons crossing the surface. The surface current above represents the neutrons moving across the surface in direction \(\hat{n}\). In order to separately compute the neutrons moving across the surface in both directions (instead of summing them implicitly), partial surface currents can be computed as

\beq
\label{eq:PartialCurrent}
J_\pm \spas = \int dA\int_{2\pi\pm}^{} d\hO   \vv{j}\spa \cdot\hat{n}
\eeq

The net current through a surface is then the sum of the two partial currents (note that \(J_+\) is positive (pointing in the positive direction) while \(J_-\) is negative (pointing in the negative direction), so that we have to actually take the difference between the two to find the net current):

\beq
\label{eq:TotalCurrent}
J \spas = J_+ - J_-
\eeq

\clearpage
\input{transport-equation.tex}

\begin{comment}
To interpret this dot product in terms of moments such as in Eq. \ref{eq:ScatteringMomentsLegendre}, we can reduce the scattering term in the above equation to the one-dimensional form:

\begin{equation}
\label{eq:1DTEScatteringIntegrated}
\begin{aligned}
\int_{4\pi}^{} d\hO   \int_{0}^{\infty}dE' \int_{4\pi}^{ } d\hO  ' \hO  \cdot\hO   \hO  \Sigma_s(\vv{r}, E'\rightarrow E, \hO  '\rightarrow\hO  )\psi\spap = \\
3\int_{4\pi}^{} d\hO   \int_{0}^{\infty}dE' \int_{4\pi}^{ } d\hO  ' \Omega_x\Omega_x\Omega_x\Sigma_s(\vv{r}, E'\rightarrow E, \hO  '\rightarrow\hO  )\psi\spap
\end{aligned}
\end{equation}
\end{comment}

\begin{comment}
Then, we can integrate out the angular dependence of the scattering term by recognizing that \(\hO  \cdot\hO  =\mu\), and so one of the areal integrals of the scattering cross section becomes equivalent to the first moment of the scattering cross section, as shown in Eq. \ref{eq:ScatteringMomentsLegendre}. Then, we can substitute in our relationship for \(\vv{j} = \psi\hO  \). This leads to another equivalent form of the transport equation:

\beqa
\label{eq:TEAngleAngleIntegrated2}
\frac{1}{v(E)} \frac{\partial\vv{J}\spas}{\partial t} +
 \nabla\cdot \int_{4\pi}^{} d\hO   \hO  \vv{j}\spa  + 
 \Sigma_t\spas\vv{J}\spas = \\
 \frac{3}{2}\int_{0}^{\infty}dE' \int_{4\pi}^{ } d\hO  ' \Sigma_{s1}(\vv{r}, E'\rightarrow E)\vv{j}(\vv{r}, E', t) + S_1\spas\\
\eeqa
\end{comment}

\subsection{Cartesian Coordinates}

\subsubsection{Integration Over Angle}

We can also integrate Eq. \ref{eq:TE_Cartesian_1D} over \(0\leq \phi \leq 2\pi\), because this will then allow the scattering term to be expressed solely in terms of \(\mu\). 

\begin{equation}
\label{eq:TE_Cartesian_1D_2}
\begin{aligned}
\frac{1}{v(E)} \frac{\partial\psi(z, E, \mu,t)}{\partial t} + \mu \frac{\partial \psi(z, E, \mu,t)}{\partial z} +
 \Sigma_t(z,E)\psi(z, E, \mu,t) =\\
 2\pi \int_{0}^{\infty}dE' \int_{-1}^{1} d\mu' \Sigma_s(z, E'\rightarrow E, \mu')\psi(z, E', \mu',t) + S(z, E, \mu, t)+\\
 \frac{\chi_p(E)}{2} \int_{0}^{\infty} dE'\nu(E')\Sigma_f(z, E')\int_{-1}^{1} d\mu'\psi(z, E', \mu',t)\\
\end{aligned}
\end{equation}

\subsubsection{Integration Over Angle and Energy}
Eq. \eqref{eq:TE_Cartesian_1D_2} can further be integrated over energy to give:

\begin{equation}
\label{eq:TE_Cartesian_1D_2_noenergy}
\begin{aligned}
\frac{1}{v} \frac{\partial\psi(z, \mu,t)}{\partial t} + \mu \frac{\partial \psi(z, \mu,t)}{\partial z} +
 \Sigma_t(z)\psi(z, \mu,t) =\\
 2\pi\int_{-1}^{1} d\mu' \Sigma_s(z, \mu')\psi(z,\mu',t) + S(z, \mu, t)+\frac{\nu\Sigma_f(z)}{2}\int_{-1}^{1} d\mu'\psi(z, \mu',t)\\
\end{aligned}
\end{equation}

\clearpage
\section{The Multigroup Transport Equation}

The multigroup transport equation can be derived by two separate means - the first involves separating all quantities into separate functions of energy and space:

\begin{equation}
\label{eq:MultiGroupSeparate}
\psi\spa  \approx f(E)\psi(\vv{r}, \hO  ,t)
\end{equation}

where

\begin{equation}
\label{eq:f_E_normalized}
\int_{g} dEf(E) = 1
\end{equation}

The second approach assumes nothing about energy-space separability by using the Legendre moments of the flux. Substituting in the approximation given by Eq. \ref{eq:MultiGroupSeparate} to the transport equation given by Eq. \ref{eq:TE} and integrating over an arbitrary energy group will lead to cross sections that depend on the function \(f(E)\), since the approximation of Eq. \ref{eq:MultiGroupSeparate} causes \(\psi\) to become independent of energy, and hence it can move outside the energy integral.

\begin{equation}
\label{eq:multigroupTE1}
\begin{aligned}
\frac{1}{v_g}\frac{\partial \psi_g(\vv{r}, \hO  , t)}{\partial t} + \hO  \cdot\nabla\psi_g(\vv{r}, \hO  , t) + \Sigma_{tg}(\vv{r})\psi_g(\vv{r}, \hO  , t) =\\
\sum_{g'=1}^{G} \int_{4\pi}^{} d\hO  ' \Sigma_{s, g'\rightarrow g}(\vv{r}, \hO  ' \rightarrow\hO  )\psi_{g'}(\vv{r}, \hO  , t) + \chi_g \sum_{g'=1}^{G}\int_{4\pi}^{} d\hO  ' \nu_{g'}\Sigma_{f,g'}(\vv{r})\psi_g(\vv{r}, \hO  ', t)
\end{aligned}
\end{equation}

The group constants depend directly on \(f(E)\). For instance, the group total cross section is

\begin{equation}
\label{eq:multigroupTE1_constants1}
\Sigma_{tg}(\vv{r}) = \int_{g} dE \Sigma_t(\vv{r}, E) f(E)
\end{equation}

This is not a very elegant way to derive the multigroup transport equation, because \(f(E)\) depends on the characteristics of the system, and will require a fine-group calculation to be collapsed to a coarse-group structure, and will require some approximation to \(f(E)\). For very fine energy groups, the simplest approximation would be to take \(f(E)\) as a constant over each energy group.

\begin{equation}
\label{eq:FineGroupf_E}
f(E) = \frac{1}{\Delta E_g}
\end{equation}

However, this is really only acceptable at lower neutron energies where the cross sections do not display large resonances and there is a relatively smooth \(1/v\) dependence. Integrating Eq. \ref{eq:multigroupTE1} over angle gives another form of the multigroup transport equation.

\begin{equation}
\label{eq:multigroupTE2}
\begin{aligned}
\frac{1}{v_g} \frac{\partial\phi_g(\vv{r}, t)}{\partial t} + \nabla\cdot\ J_g(\vv{r}, t) + \Sigma_{tg}(\vv{r})\phi_g(\vv{r}, t) =\\
\sum_{g'=1}^{G} \Sigma_{s, g'\rightarrow g}(\vv{r})\phi_{g'}(\vv{r}, t) + \chi_g \sum_{g'=1}^{G} \nu_{g'}\Sigma_{f,g'}(\vv{r})\phi_{g'}(\vv{r}, t)
\end{aligned}
\end{equation}

\clearpage
\input{eigenvalue.tex}

\clearpage
\section{The Adjoint Neutron Transport Equation}

The adjoint form of an operator \(\zeta\) is defined such that the inner product, defined in Eq. \ref{eq:innerproduct}, gives:

\begin{equation}
\label{eq:AdjointDefinition}
<w, \zeta u> = <u, \zeta^\dagger w>
\end{equation}

where \(\zeta^\dagger\) is the adjoint form of \(\zeta\). An operator is self-adjoint if \(\zeta=\zeta^\dagger\). The adjoint flux, or the solution to the adjoint neutron transport equation, can be interpreted as an importance function relative to a desired physical quantity, such as a tally response, and are therefore useful for variance reduction methods in Monte Carlo simulations. In addition, the adjoint function is central to perturbation theory and variational methods. To contrast with the adjoint transport equation, the transport equation discussed in this document thus far is sometimes referred to as the forward transport equation, as opposed to the ``backward'' transport equation. 

To find the adjoint of an operator \(\zeta\), applied to an arbitrary function \(u\), we take the inner product of \(w\) with \(\zeta u\), and then use integration by parts and other properties, such as the divergence theorem, to switch the operation as much as possible from \(u\) to \(w\). When this is complete, and \(u\) is free from any operator action, then the operator acting on \(w\) is the adjoint of \(\zeta\). In general, due to the integration by parts, \(\zeta\) will not equal \(\zeta^\dagger\) exactly due to boundary terms \(P[u,w]\). Without regard to boundary conditions, \(\zeta^\dagger\) is technically the formal adjoint of \(\zeta\). If \(\zeta=\zeta^\dagger\), the operator is formally self-adjoint.

\begin{equation}
\label{eq:FormalAdjointDefinition}
<w, \zeta u> = P[u,w] + <u, \zeta^\dagger w>
\end{equation}

\begin{tcolorbox}[breakable]
An example derivation of the adjoint of an operator is useful to illustrate how it is determined. Consider the second-order operator \(\zeta\) acting on \(u\):

\begin{equation}
\zeta u=a_2(x)\frac{d^2u(x)}{dx^2}+a_1(x)\frac{du(x)}{dx}+a_0(x)u(x)
\end{equation}

To determine the adjoint of \(\zeta\), take the inner product of the above with an arbitrary function \(w\), and integrate by parts as much as possible to switch the operator to \(w\) from \(u\).

\begin{equation}
\begin{aligned}
<w,\zeta u> = & <w, \zeta_2 u> + <w, \zeta_1 u> + <w, \zeta_0 u>\\
= & \int \left(a_2(x)\frac{d^2u(x)}{dx^2}w(x)+a_1(x)\frac{du(x)}{dx}w(x)+a_0u(x)w(x)\right)dx\\
= & \int_a^b \left(-\frac{du(x)}{dx}\frac{d}{dx}\left\lbrack a_2(x)w(x)\right\rbrack -u(x)\frac{d}{dx}\left\lbrack a_1(x)w(x)\right\rbrack + a_0(x)u(x)w(x)\right) dx\\ 
& + \left\lbrack w(x)a_2(x)\frac{du(x)}{dx}+a_1(x)u(x)w(x)\right\rbrack_a^b\\
= & \int_a^b \left(u(x)\frac{d^2}{dx^2}\left\lbrack a_2(x)w(x)\right\rbrack-u(x)\frac{d}{dx}\left\lbrack a_1(x)w(x)\right\rbrack + a_0(x)u(x)w(x)\right)dx\\
& + \underbrace{\left\lbrack w(x)a_2(x)\frac{du(x)}{dx}+a_1(x)u(x)w(x)-\frac{d}{dx}\left\lbrack a_2(x)w(x)\right\rbrack u(x)\right\rbrack_a^b}_{P[u,w]}\\
\end{aligned}
\end{equation}

So, the adjoint of \(\zeta\) is:

\begin{equation}
\zeta^\dagger w= \frac{d^2}{dx^2}\left\lbrack a_2(x)w(x)\right\rbrack -\frac{d}{dx}\left\lbrack(a_1(x)w(x)\right\rbrack+a_0(x)w(x)+P[u,w]
\end{equation}

And so, of these operators, only the multiplication is self-adjoint. The second derivative operator is self-adjoint if \(a_2\) is constant such that one of the boundary terms drops out, and if the second derivative appears in the symmetric form, which in general three dimensions equates to \(\nabla\cdot(a_2\nabla \phi)\), as opposed to the non-symmetric form (\(a_2\nabla^2 \phi\)). Despite these limitations, any second-order operator can be converted to a self-adjoint form using an appropriate transformation of coefficients. This is the basis by which the optimal weighting parameters are determined for one-dimensional upwinding stabilization schemes used for the Navier-Stokes equations - optimal stabilization occurs when the equation is forced to be self-adjoint. To select the boundary conditions, a consistent set of conditions can be obtained by requiring the entirety of the boundary functional \(P[u,w]\) to vanish. 
\end{tcolorbox}

The adjoint neutron transport equation can be derived by multiplying Eq. \ref{eq:TE} by an arbitrary weight function \(w\), then integrating each term by parts, switching the operators to act on \(w\) alone. Because the adjoint equation will be in terms of \(w\), to allow this to have more physical intuitive meaning that a simple weight function, we will multiply each term by \(\psi^\dagger\), since we will show that this weight function then actually becomes our interpretation of the adjoint flux. This is nothing more than a notation change from that in Eq. \ref{eq:AdjointDefinition}. This process will be completed in parts and then all terms will be summed in the end to give the total adjoint equation. Integration over the entire phase space will be represented short-hand by:

\begin{equation}
\label{eq:PhaseSpaceIntegration}
\int d\oslash = \int dVdEd\hO  dt
\end{equation}

where for simplicity the generic phase space is denoted as \(\oslash\). This derivation is performed in parts due to the linearity of the transport equation.

\begin{enumerate}
\item The time-dependent term becomes:

\begin{equation}
\label{eq:AdjointTime}
\begin{aligned}
<\psi^\dagger, \zeta_t\psi> = & \int d\oslash \psi^\dagger \frac{1}{v} \frac{\partial\psi}{\partial t}\\
= & -\int d\oslash \frac{\partial}{\partial t} \left(\frac{1}{v}\psi^\dagger\right)\psi + [\psi^\dagger \frac{1}{v} \psi]\\
= & <\psi, \zeta^\dagger\psi^\dagger> + \int_{\partial\oslash}\psi^\dagger \frac{1}{v} \psi
\end{aligned}
\end{equation}

where the adjoint form of the time operator is:

\begin{equation}
\zeta^\dagger = -\frac{\partial}{\partial t}\left\lbrack\frac{1}{v}(.)\right\rbrack
\end{equation}

The time-dependent term is non-self adjoint, since the boundary term, which integrates from \(t_o\) to \(t_f\), is in general nonzero. This boundary term is a boundary term in \textit{time}, and not in space - hence, it only takes values at the start and end of the domain. In addition, the adjoint form of the operator, without the boundary term, is the negative of the forward form. 

\item The removal term becomes:

\begin{equation}
\begin{aligned}
<\psi^\dagger,\zeta_r\psi>= & \int d\oslash \psi^\dagger \Sigma_t\psi\\
= & <\psi,\zeta^\dagger\psi^\dagger>\\
\end{aligned}
\end{equation}

where the adjoint form of the removal operator is self-adjoint:

\begin{equation}
\zeta_r=\Sigma_t(.)
\end{equation}

\item The streaming (leakage) term becomes:

\begin{equation}
\begin{aligned}
<\psi^\dagger,\zeta_l\psi>= & \int d\oslash \psi^\dagger\hO  \cdot\nabla\psi\\
= & \int d\oslash \left(\nabla\cdot(\hO  \psi\psi^\dagger)-\psi\hO  \cdot\nabla\psi^\dagger\right)\\
= & -\int d\oslash \left(\hO  \psi\psi^\dagger +\psi\hO  \cdot\nabla\psi^\dagger\right)+ \int_{\partial\oslash}\hO  \psi\psi^\dagger\cdot\hat{n}\\
\end{aligned}
\end{equation}

where the first step applies an identity to the dot product, and second the divergence theorem. The streaming term is non-self-adjoint. The adjoint form of the streaming term is:

\begin{equation}
\zeta_l=-\hO  (.)-\hO  \cdot\nabla(.)+\left\lbrack\hO  (.)\right\rbrack
\end{equation}

\item The (in)scattering term becomes:

\begin{equation}
\begin{aligned}
<\psi^\dagger,\zeta_s\psi>=& \int d\oslash\psi^\dagger\spa \int_0^\infty dE'\int_{4\pi}d\hO  ^{'}\Sigma_s(\hO  ^{'}\rightarrow\hO  , E^{'}\rightarrow E)\psi(\vv{r},\hO  ^{'},E^{'},t)\\
=& \int d\oslash\int_0^\infty dE\int_{4\pi}d\hO  \psi^\dagger\spa \Sigma_s(\hO  ^{'}\rightarrow\hO  , E^{'}\rightarrow E)\psi(\vv{r},\hO  ^{'},E^{'},t)\\
=& \int d\oslash\int_0^\infty dE^{'}\int_{4\pi}d\hO  ^{'}\psi^\dagger(\vv{r},\hO  ^{'},E^{'},t)\Sigma_s(\hO  \rightarrow\hO  ^{'}, E\rightarrow E^{'})\psi\spa \\
=& \int d\oslash\psi\spa \int_0^\infty dE^{'}\int_{4\pi}d\hO  ^{'}\psi^\dagger(\vv{r},\hO  ^{'},E^{'},t)\Sigma_s(\hO  \rightarrow\hO  ^{'}, E\rightarrow E^{'})\\
=& <\psi, \zeta_s^\dagger\psi^\dagger>
\end{aligned}
\end{equation}

where the adjoint form of the scattering operator is:

\begin{equation}
\zeta_s^\dagger= \int_0^\infty dE^{'}\int_{4\pi}d\hO  ^{'}(.)\Sigma_s(\hO  \rightarrow\hO  ^{'}, E\rightarrow E^{'})
\end{equation}

First, the order of integration of the pre- and post-collision energies and angles are interchanged, since integrating over either all of the starting energies, or all of the ending energies, will equally capture the total number of scattering interactions. Then, the adjoint flux must be moved inside of the integration, since it depends on the variables of integration. Second, the symbols for the pre- and post-collision energies and angles are swapped, since the symbols are dummy symbols. Finally, the forward flux is brought outside the integral. The adjoint of the scattering operator is obtained by simply reversing the order of the pre- and post-collision energies and angles. Scattering is generally rotationally symmetric (dependent on only one angle), so this only impacts the energy loss portion of the kernel. If there is no energy loss in scattering, such as in coherent scattering, then the scattering operator is self-adjoint. However, if there is energy loss in scattering, then the scattering operator is non-self-adjoint.

\item The fission term becomes:

\begin{equation}
\begin{aligned}
<\psi^\dagger,\zeta_f\psi>=& \int d\oslash\psi^\dagger\spa \frac{\chi_p(E)}{4\pi}\int_0^\infty dE^{'}\int_{4\pi}d\hO  ^{'}\nu\Sigma_f(E^{'})\psi(\vv{r},\hO  ^{'},E^{'},t)\\
=& \int d\oslash\int_0^\infty dE\int_{4\pi}d\hO  \psi^\dagger\spa \frac{\chi_p(E)}{4\pi}\nu\Sigma_f(E^{'})\psi(\vv{r},\hO  ^{'},E^{'},t)\\
=& \int d\oslash\psi\spa \nu\Sigma_f(E)\int_0^\infty dE^{'}\int_{4\pi}d\hO  ^{'}\psi^\dagger(\vv{r},\hO  ^{'},E^{'},t)\frac{\chi_p(E^{'})}{4\pi}\\
=& <\psi,\zeta^\dagger\psi^\dagger>\\
\end{aligned}
\end{equation}

where the adjoint form of the fission operator is:

\begin{equation}
\zeta_f^\dagger=\nu\Sigma_f(E)\int_0^\infty dE^{'}\int_{4\pi}d\hO  ^{'}(.)\frac{\chi_p(E^{'})}{4\pi}\\
\end{equation}

In a similar process as that performed for the scattering term, first the pre- and post-collision energy and angular variables are switched, since integration over either all of the starting energies, or over all of the ending energies, will still fully account for all fission events. Then, the dummy variables for pre- and post-collision energies and angular variables are swapped, whereupon the forward flux can be brought outside the integration. The fission operator is also non-self adjoint with respect to energy, since the angular distribution of fission neutrons is assumed isotropic. This operator becomes self-adjoint if all neutrons are born with the same energy (\(\chi_p=1\)) and the fission cross section is energy-independent. These are both true for the one-speed approximation.
\end{enumerate}

The adjoint neutron transport equation becomes, summing all of these terms together:

\begin{equation} % verify
\begin{aligned}
-\frac{1}{v}\frac{\partial\psi^\dagger\spa }{\partial t}
& -\hO  \cdot\nabla\psi^\dagger\spa 
+\Sigma_t\psi^\dagger\spa =\\
& \int_0^\infty dE^{'}\int_{4\pi}d\hO  ^{'}\psi^\dagger\spa \Sigma_s(\hO  \rightarrow\hO  ^{'}, E\rightarrow E^{'})+\\
& \nu\Sigma_f(E)\int_0^\infty dE^{'}\int_{4\pi}d\hO  ^{'}\psi^\dagger\spa \frac{\chi_p(E^{'})}{4\pi} + Q^\dagger\spa \\
\end{aligned}
\end{equation}

for an adjoint source \(Q^\dagger\) and appropriate boundary and initial conditions. The solution to the adjoint transport equation is the adjoint flux, which represents a flow of pseudo-particles that differ from the transport of neutrons in several important ways. The adjoint particles

\begin{itemize}
\item Are born in the phase space according to the adjoint source, and are born at some terminal time
\item Stream in reverse directions to earlier times (from the adjoint form of the leakage term)
\item Gain energy in collisions (from the adjoint form of the scattering term), but the inscattering and outscattering terms don't balance, since the outscattering term is self-adjoint while the inscattering term is not unless there is no energy loss in scattering. Hence, the energy-dependent form of the adjoint equation is nonconservative!
\item Are emitted isotropically in fission, but the fission cross section is proportional to the energy spectrum of the fission neutrons being born, instead of on the starting neutron energy. The spectrum of the adjoint fission particles depends on the neutron fission energy.
\end{itemize}

Based on these interpretations, it is clear why the adjoint transport equation is often referred to as the backward transport equation. The dominant eigenvalue of the adjoint problem is equivalent to that of the forward problem. In a bare reactor, the adjoint flux and flux actually have the same exact profile. 

The adjoint neutron transport equation can in some situations lead to a more efficient solution to a physical problem than the traditional forward approach. Both the forward and adjoint problems satisfy the following generic statement:

\begin{equation}
\begin{aligned}
\zeta\psi=& Q\\
\zeta^\dagger\psi^\dagger=& Q^\dagger\\
\end{aligned}
\end{equation}

Taking the inner product of the first of these equations with the adjoint flux, and the inner product of the second of these equations with the forward flux:

\begin{equation}
\begin{aligned}
<\zeta\psi,\psi^\dagger>=& <\psi^\dagger,Q>\\
<\zeta^\dagger\psi^\dagger,\psi>=& <\psi,Q^\dagger>\\
\end{aligned}
\end{equation}
 
 Subtracting these two equations from each other:
 
 \begin{equation}
 <\zeta\psi,\psi^\dagger>-<\zeta^\dagger\psi^\dagger,\psi>=<\psi^\dagger,Q>-<\psi,Q^\dagger>
 \end{equation}

The only two terms in the transport equation that had resulting boundary terms were the time and streaming terms. The LHS above equals zero if those boundary terms are zero. In general, however, the above simplifies to:

\begin{equation}
\label{eq:ReciprocityCondition}
\begin{aligned}
<\psi^\dagger,Q>-<\psi,Q^\dagger> \ =& \int_0^\infty dE\int_{4\pi}d\hO  \int dV\psi^\dagger \spa \frac{1}{v} \psi\spa \biggr\rvert_{0}^{t=T} +\\
& \int_0^{T}dt\int_0^\infty dE\int d\hO  \int_{\partial V}dA\hat{n}\cdot\hO  \psi\spa \psi^\dagger\psi\spa \biggr\rvert_{\hat{n}\cdot\hO  <0}^{\hat{n}\cdot\hO  >0}
\end{aligned}
\end{equation}

Eq. \eqref{eq:ReciprocityCondition} is often referred to as the ``reciprocity condition.'' So, the functionals of the forward and adjoint fluxes are related at initial and final times along incoming and outgoing directions at the surface of the body with those functionals on the interior of the body with fixed sources. This allows transport problems to be posed as either forward or adjoint. 

\subsection{Source-Detector Problems}

The adjoint form of the neutron transport equation is widely used for source-detector problems, where a given source distribution and free surface boundary condition is used to compute the response of a detector. The ``response'' of a detector is typically some quantity of interest that is proportional to the neutron flux, such as the flux itself or a reaction rate. The response of a detector is, in general simply an inner product of the flux with some parameter \(f\) over the body \(R\) of the detector:

\begin{equation}
\label{eq:Response}
\textrm{Response}=\int_0^\infty dE\int_{4\pi}d\hO  \int_RdVf(\vv{r},\hO  ,E)\psi(\vv{r},\hO  ,E)
\end{equation}

For instance, to calculate the absorption rate in the detector, \(f\) would be \(\Sigma_a\). Note that the use of the word ``detector'' simply refers to the fact that adjoint problems are usually applied to realistic problems, where the quantity measured by a detector is to be predicted. Source-detector problems are often assumed to be in steady-state, whereupon the time terms in Eq. \eqref{eq:ReciprocityCondition} are eliminated to give:

\begin{equation}
\label{eq:ReciprocityCondition2}
<\psi^\dagger,Q>-<\psi,Q^\dagger> \ = \int_0^{T}dt\int_0^\infty dE\int d\hO  \int_{\partial V}dA\hat{n}\cdot\hO  \psi\spa \psi^\dagger\psi\spa \biggr\rvert_{\hat{n}\cdot\hO  <0}^{\hat{n}\cdot\hO  >0}
\end{equation}

If we require that the outward-directed adjoint flux at the boundary is zero, then the term on the RHS also goes to zero. Finally, because the adjoint source is arbitrary, we can specify that it is to be the detector response. These two assumptions lead Eq. \eqref{eq:ReciprocityCondition2} to simplify to:

\begin{equation}
\label{eq:ReciprocityCondition3}
<\psi^\dagger,Q>=<\psi,f>
\end{equation}

This shows that the desired detector response (\(<f,\psi>\) from Eq. \eqref{eq:Response}) can be expressed as the inner product of the adjoint flux with the physical source. The adjoint flux is determined by solving the adjoint neutron transport equation, with \(Q^\dagger=f\) and \(\psi^\dagger=0\) for \(\hO  \cdot\hat{n}>0\) on the boundary of the detector region. 

This adjoint formulation is very useful for two reasons. First, the adjoint flux is independent of the actual source distribution - it only depends on the detector response. So, a single adjoint calculation can be performed in order to calculate the adjoint flux for any number of physical sources. It is easier to evaluate the inner product of the adjoint flux and the physical source than to perform multiple forward calculations. 

Second, the adjoint flux can be interpreted as an importance function. Suppose the forward source consists of a single particle injected into phase space with a given position, direction, and energy:

\begin{equation}
Q=\delta(\vv{r}-\vv{r}_0)\delta(\hO  -\hO  _0)\delta(E-E_0)
\end{equation}

Then, from Eq. \eqref{eq:ReciprocityCondition3}, the detector response is equal to the adjoint flux at the point of injection of the forward neutron. So, the adjoint flux is often interpreted as the importance of forward neutrons at those locations to a contribution towards the detector response. The \(\psi^\dagger=0\) outgoing boundary condition also supports this interpretation, since neutrons leaving the boundary of the system obviously have no impact on the flux or reaction rates within the body. 

\begin{equation}
\label{eq:ReciprocityCondition3}
\psi^\dagger(\vv{r}_0,\hO  _0,E_0)=<\psi,f>
\end{equation}

\subsection{Acceleration of Monte Carlo Computations}

The adjoint form of the neutron transport equation is often used to accelerate Monte Carlo calculations by reducing the variance of the statistical results, requiring less particle histories to be run to obtain the same level of accuracy. Note that the actual computation time for the same number of histories is reduced - the ``acceleration'' comes from the fact that less overall histories will need to be run. The objective of using a deterministic calculation to accelerate Monte Carlo computations is to developed an importance function that represents the importance of particles to a particular tally response. 

These methods use a forward deterministic calculation to generate a forward-weighted source for a deterministic adjoint calculation. The adjoint calculation then results in an adjoint flux that is used to generate consistent space- and energy-dependent source biasing parameters and weight windows that are used in forward Monte Carlo calculations to achieve effective variance reduction. 

Source biasing is the process by which the original forward source which is known to the modeler is changed such that the source contains a higher proportion of particles that are significant with respect to the objective tally. For example, if a physical problem consists of two neutrons sources, one fully exposed and the other highly shielded, the fully-exposed neutrons are the only neutrons that will contribute significantly to a flux tally in the domain. So, instead of using both sources, the source may be biased to only contain the fully exposed source. Knowledge of the important particles for more complex problems can be estimated using the adjoint flux and the forward source as described in the previous section. 

\subsubsection{CADIS}

The CADIS method generates a biased source \(\hat{q}\) from the forward source \(q\), where that biased source is weighted by the adjoint flux and normalized by the detector response:

\begin{equation}
\label{eq:CADIS}
\begin{aligned}
\hat{q}= \frac{\psi^\dagger(\vv{r},\hO  ,E)q(\vv{r},\hO  ,E)}{\int_{4\pi}\hO  \int dE\int_RdV\psi^\dagger(\vv{r},\hO  ,E)q(\vv{r},\hO  ,E)}= \frac{\psi^\dagger(\vv{r},\hO  ,E)q(\vv{r},\hO  ,E)}{\textrm{Response}}\\
\end{aligned}
\end{equation}

where \(R\) is the detector physical bounds. This is an intuitive biasing, since the source particles are biased according to their contribution to the detector response. Because the biased source particles are sampled from a biased probability density function, their statistical weight also must be corrected such that the product of the weight and source is equivalent for both no biasing and biasing, a basic statement of conservation of the number of particles:

\begin{equation}
\label{eq:WeightsCADIS}
w(\vv{r},\hO  ,E)\hat{q}(\vv{r},\hO  ,E)=w_0q(\vv{r},\hO  ,E)
\end{equation}

where \(w\) and \(w_0\) reflect particle weights. Substituting the biased source from Eq. \eqref{eq:CADIS} into Eq. \eqref{eq:WeightsCADIS} gives the second equivalent form for the new biased particle weights:

\begin{equation}
\label{eq:WeightsCADIS2}
w(\vv{r},\hO  ,E)=\frac{w_0\textrm{Response}}{\psi^\dagger(\vv{r},\hO  ,E)}
\end{equation}

Hence, the statistical weight is inversely proportional to the importance function. This method is ``consistent'' because the particle weights are consistent with those used in source sampling and the particle transport process.

\subsubsection{FW-CADIS}

One rough method for obtaining uniform uncertainty throughout a domain is to obtain a uniform distribution of particles throughout the system. This should \textit{roughly} lead to equally-merited statistics throughout the domain. The FW-CADIS method is based upon the objective of developing an importance function that represents the importance of particles to achieving a uniform distribution throughout the domain. Then, instead of optimizing a detector response, we optimize for the particle density throughout the domain by setting \(f\) in Eq. \eqref{eq:Response} such that the response represents the particle density throughout the domain. This function \(f\) must convert flux to Monte Carlo particle density. The physical particle density \(n\) is equal to the product of the average particle weight \(\bar{w}\) with the Monte Carlo particle density \(m\):

\begin{equation}
n(\vv{r},\hO  ,E)=\bar{w}(\vv{r},\hO  ,E)m(\vv{r},\hO  ,E)
\end{equation}

And the angular flux is defined as \(\psi=nv\), where \(v\) is the particle velocity. The Monte Carlo particle density can be estimated by combining these two definitions:

\begin{equation}
\label{eq:MCDensity}
m(\vv{r},\hO  ,E)=\frac{\psi(\vv{r},\hO  ,E)}{\bar{w}(\vv{r},\hO  ,E)v(\vv{r},\hO  ,E)}
\end{equation}

The total Monte Carlo particle density is obtained by integrating Eq. \eqref{eq:MCDensity} over the entire domain. If the average particle weight is set proportional to the physical particle density \(n\), then the Monte Carlo particle density should be nearly uniform. In this case, \(\bar{w}\) can be replaced by \(n\) in Eq. \eqref{eq:MCDensity}, giving the following optimized response:

\begin{equation}
\label{eq:FWCADISResponse}
\textrm{Response}=\int_0^\infty dE\int_{4\pi}d\hO  \int_RdV\psi(\vv{r},\hO  ,E)\left(\frac{1}{\psi(\vv{r},\hO  ,E)}\right)
\end{equation}

From Eq. \eqref{eq:ReciprocityCondition2}, Eq. \eqref{eq:FWCADISResponse} is effectively setting the adjoint source equal to the inverse of the forward flux. So, the FW-CADIS method computes the adjoint source as the inverse of the forward flux in an effort to obtain approximately uniform statistical uncertainties. Once this adjoint source is used to compute the adjoint flux, the CADIS method is executed to calculate consistent source biasing parameters.

\clearpage
\section{The Self-Adjoint Angular Flux (SAAF) Equation}

The SAAF equation, though it has a name very similar to the adjoint neutron transport equation, is a fairly different concept, and does not consider the adjoint operators in its derivation. Do not confuse the two formulations, for they are different. The SAAF equation can be very easily derived symbolically starting from the time-independent version of Eq. \ref{eq:TE}, where the combined effects of absorption and scattering removal are bundled into a removal operator, which contains the scattering operator \(S\) that performs the action of the scattering integral on the flux:

\begin{equation}
\label{eq:SAAFRemovalOperator}
R = (\Sigma_t - S)
\end{equation}

All fission sources are bundled into the source \(Q\). This simplified transport equation is:

\begin{equation}
\label{eq:SAAFStart}
\hO  \cdot\nabla\psi(\vv{r}, \hO  , E) + R\psi(\vv{r}, \hO  , E) = Q
\end{equation}

Solving this equation symbolically for \(\psi\) in terms of \(\nabla\psi\):

\begin{equation}
\label{eq:SAAFStep1}
\psi(\vv{r}, \hO  , E) = R^{-1}\left(Q-\hO  \cdot\nabla\psi(\vv{r}, \hO  , E)\right)
\end{equation}

Then, substituting this back into Eq. \ref{eq:SAAFStart} for \(\psi\) gives the SAAF equation:

\begin{equation}
\label{eq:SAAF}
\hO   \cdot \nabla \left( R^{-1}\left(Q-\hO  \cdot\nabla\psi(\vv{r}, \hO  , E)\right)\right) + R\psi(\vv{r}, \hO  , E) = Q
\end{equation}

The advantage of the SAAF equation is that it allows us to apply the Galerkin finite element method while maintaining Symmetric Positive Definite (SPD) characteristics. We still need a formal definition for the inverse of the removal operator. Multiplying the time-independet form of Eq. \ref{eq:TEPLnomoments} (with the fission and external source replaced by \(Q\) as in Eq. \ref{eq:SAAF}) by \(Y_l^{m*}(\hO  )\) and integrating over angle, after applying the spherical harmonics orthogonality condition given by Eq. \ref{eq:SHOrthogonality} gives (after also removing the energy-dependence from the scattering moment)

\begin{equation}
\label{eq:RemovalOperatorDerivation1}
\begin{aligned}
 \int_{4\pi}^{}d\hO   \psi\spa Y_l^{m*}(\hO  ) = \\
 (\Sigma_t(\vv{r},E) - \Sigma_{s,l}(\vv{r}))^{-1}\int_{4\pi}^{} d\hO  Y_l^{m*}(\hO  ) \left(Q - \hO  \cdot\nabla\psi\spa \right)
\end{aligned}
\end{equation}

Replacing the angle integral term in the time-independet form of Eq. \ref{eq:TEPLnomoments} (with the fission and external source replaced by \(Q\) as in Eq. \ref{eq:SAAF}) by Eq. \ref{eq:RemovalOperatorDerivation1}, and then solving for \(\psi\):

\begin{equation}
\label{eq:RemovalOperatorDerivation2}
\begin{aligned}
\psi(\vv{r}, \hO  , E) = \frac{1} {\Sigma_t(\vv{r}, E)} \left(Q - \hO  \cdot\nabla\psi(\vv{r}, \hO  , E)\right) +\\
\frac{1}{\Sigma_t(\vv{r}, E)} \int_{0}^{\infty}dE' \sum_{l=0}^{L} \frac{\Sigma_{s,l}(\vv{r}, E)}{\Sigma_t(\vv{r}, E) - \Sigma_l(\vv{r}, E)} \sum_{m=-l}^{l}  Y_{lm}(\hO  ) \int_{4\pi}^{} d\hO  ' Y_l^{m*}(\hO  ') \left(Q(\vv{r}, \hO  ') - \hO  '\cdot\nabla\psi(\vv{r}, \hO  ', E)\right)
\end{aligned}
\end{equation}

By combining Eqs. \ref{eq:RemovalOperatorDerivation2} and \ref{eq:SAAFStep1} gives the form of the inverse of the removal operator:

\begin{equation}
\label{eq:RemovalOperatorDerivation3}
R^{-1} f(\vv{r}, \hO  ) = \frac{1}{\Sigma_t(\vv{r}, E)} \left(f(\vv{r}, \hO  ) + \sum_{l=0}^{L} \frac{\Sigma_{s,l}(\vv{r}, E)}{\Sigma_t(\vv{r}, E) - \Sigma_l(\vv{r}, E)}\sum_{m=-l}^{l}  Y_{lm}(\hO  )\int_{4\pi}^{} d\hO  ' Y_l^{m*}(\hO  ') f(\vv{r}, \hO  )\right)
\end{equation}

Because the SAAF is second order, we require one extra boundary condition above that which would be required for the 1st-order transport equation. We can require this boundary condition to be on the outgoing flux, where we simply require the outgoing flux for the SAAF equation to match the flux from the 1st-order transport equation at the boundary. Using this extra boundary condition should allow us to eliminate the extra solutions that are permitted by a second order equation over a first order equation. As can be seen from Eq. \ref{eq:RemovalOperatorDerivation3}, the SAAF equation as it stands in Eq. \ref{eq:SAAF} cannot be used in void regions with zero \(\Sigma_t\). Hence, we need a special void treatment. In a void, we can set the source equal to zero. Then, Eq. \ref{eq:SAAF} becomes:

\begin{equation}
\label{eq:SAAFvoid1}
\hO   \cdot \nabla \left( \frac{1}{\Sigma_a}\left(-\hO  \cdot\nabla\psi(\vv{r}, \hO  , E)\right)\right) + \Sigma_a\psi(\vv{r}, \hO  , E) = 0
\end{equation}

Although \(\Sigma_a\) is also zero in a void, we have not set it equal to zero above. Now, taking the limit as \(\Sigma_a\) tends to zero:

\begin{equation}
\label{eq:SAAFvoid2}
-\hO   \cdot \nabla\hO  \cdot\nabla\psi(\vv{r}, \hO  , E) = 0
\end{equation}

This represents the void form of the SAAF equation to be used in voids.



\clearpage
\section{Nonlinear Diffusion Acceleration (NDA)}


NDA, also known as Coarse Mesh Finite Difference (CMFD), uses a two-equation system consisting of the transport equation and a transport-corrected diffusion equation to accelerate the solution of transport problems. As much as possible, the lower-order equation is solved, with periodic iterative corrections with transport updates, to reduce overall computation time had we only been solving the transport equation. Picard iterations (at a fixed point) are used to update the lower-order equation when necessary. 


\clearpage
\section{Collocation Angular Methods}

For all collocation in angle methods, the scattering and source terms (the only two sources that depend on angle, since the fission source is normally taken as isotropic), as well as the angular flux, are expanded in spherical harmonics. 

\clearpage
\input{discrete-ordinates.tex}

\subsubsubsection{Cell Balance Schemes}

Cell balance schemes point values for the solution \(\psi\) over a discretized spatial mesh. With the definitions in Eq. \eqref{eq:OmegaComponentsCartesian} switched around to be consistent with the Denovo manual, integrating Eq. \eqref{eq:SimpleTE} over the mesh cell shown in Fig. \ref{fig:CartesianDiscretization} gives:

\begin{equation}
\int_{x_{i-1/2}}^{x_{i+1/2}}dx\mu \frac{\partial \psi}{\partial x}+\int_{y_{j-1/2}}^{y_{j+1/2}}dy\eta \frac{\partial \psi}{\partial y}+\int_{z_{k-1/2}}^{z_{k+1/2}}dz\xi \frac{\partial \psi}{\partial z}+\Sigma_{t,ijk}{E}\psi_{ijk}(\vv{r},E)=S_{ijk}(E)
\end{equation}

where it has been assumed that \(\Sigma_t\) and \(S\) are constant over the cell, and are represented by their cell-centered values. In addition, the energy-dependence has been dropped, though the dependency could easily be re-introduced by simply carrying around the \((E, t)\) notation after each occurrence of \(\psi\). Without approximation, the integrals in the above reduce to:

\begin{equation}
\label{eq:DiscretizedCartesianTE}
\frac{\mu}{\Delta_i}(\psi_{i+1/2}-\psi_{i-1/2})+\frac{\eta}{\Delta_j}(\psi_{j+1/2}-\psi_{j-1/2})+\frac{\xi}{\Delta_k}(\psi_{k+1/2}-\psi_{k-1/2})+\Sigma_{t,ijk}\psi_{ijk}=S_{ijk}
\end{equation}

With this discretization method, there must be some way to relate the cell-centered value \(ijk\) to the face values. The different options we have for discretization are related to the choices we can make for how to relate these quantities. The Diamond Difference and Step Difference schemes choose the following relationship:

\begin{equation}
\label{eq:DifferencingRelationship}
\psi_{i\pm1/2}=\frac{2}{1\pm\alpha}\psi_{ijk}-\frac{1\mp\alpha}{1\pm\alpha}\bar{\psi}_{i\mp1/2}
\end{equation}

and likewise for the \(y\) and \(z\) directions. \(\bar{\psi}\) represents a known flux, and depending on whether a sweep is being performed in the positive-\(\mu\) direction (\(\bar{\psi}_{i-1/2}\) is known) or in the negative-\(\mu\) direction (\(\bar{\psi}_{i+1/2}\) is known), either the + or - option is selected in Eq. \eqref{eq:DifferencingRelationship}. The objective is to choose the correct relationship in Eq. \eqref{eq:DifferencingRelationship} such that the known quantities, or the incoming fluxes to each cell, can be used to compute the unknown quantities, or the outgoing fluxes for each cell, in a ``sweep'' over the spatial mesh. For example, for a sweep in the positive-\(\mu\) direction, we supposedly know \(\bar{\psi}_{i-1/2}\), so we would relate the cell-centered flux to the outgoing flux in the following way:

\begin{equation}
\begin{aligned}
\psi_{i+1/2}=\frac{2}{1+\alpha}\psi_{ijk}-\frac{1-\alpha}{1+\alpha}\bar{\psi}_{i-1/2}\quad\quad\mu >0\\
\psi_{ijk}=\frac{1}{2}\left\lbrack(1+\alpha)\psi_{i+1/2}+(1-\alpha)\bar{\psi}_{i-1/2}\right\rbrack\\
\end{aligned}
\end{equation}

Likewise, for a sweep in the negative-\(\mu\) direction, we supposedly know \(\bar{\psi}_{i+1/2}\), so we would relate the cell-centered flux to the outgoing flux in the following way:

\begin{equation}
\begin{aligned}
\psi_{i-1/2}=\frac{2}{1-\alpha}\psi_{ijk}-\frac{1+\alpha}{1-\alpha}\bar{\psi}_{i+1/2}\quad\quad\mu <0\\
\psi_{ijk}=\frac{1}{2}\left\lbrack(1+\alpha)\psi_{i+1/2}+(1-\alpha)\bar{\psi}_{i-1/2}\right\rbrack\\
\end{aligned}
\end{equation}

Note that both of these provide equivalent expressions, but the choice depends on the sweep direction. The differencing scheme in Eq. \eqref{eq:DifferencingRelationship} is a Crank-Nicolson method in space. Inserting Eq. \eqref{eq:DifferencingRelationship} into the discretized transport equation in Eq. \eqref{eq:SimpleTE} gives the following equation for the cell-centered flux in terms of known quantities:

\begin{equation}
\label{eq:psi_ijk}
\psi_{ijk}=\frac{S_{ijk}+\frac{2}{1\pm\alpha}\left(\frac{|\mu|}{\Delta_i}\bar{\psi}_{i\mp1/2}+\frac{|\eta|}{\Delta_j}\bar{\psi}_{j\mp1/2}\right)+\frac{|\xi|}{\Delta_k}\bar{\psi}_{k\mp1/2}}{\Sigma_{t,ijk}+\frac{2}{1\pm\alpha}\left(\frac{|\mu|}{\Delta_i}+\frac{|\eta|}{\Delta_j}+\frac{|\xi|}{\Delta_k}\right)}
\end{equation}

where it has been assumed that \(\alpha\) is selected to be the same in all directions. \(\alpha\) is a parameter used to tune the spatial discretization. Common choices for \(\alpha\) have their own names. The Diamond Difference method sets \(\alpha=0\). With this choice, the cell-centered flux is an average of the face fluxes. The Step Difference method, on the other hand, sets \(\alpha=\pm1\) such that the cell-centered flux is set equal to the incoming face flux (choose 1 or -1 accordingly so that Eq. \eqref{eq:DifferencingRelationship} provides an expression for \(\psi_{ijk}\) in terms of the known incoming face flux).The Diamond Difference method is second-order in space, while the Step Difference method is only first-order. 

In a ``transport sweep,'' computation begins at a boundary for which the boundary condition is known. At this boundary, the incoming fluxes are known. Then, Eq. \eqref{eq:psi_ijk} is used to solve for \(\psi_{ijk}\) using the incoming flux values. Once the cell-centered flux is known, Eq. \eqref{eq:DifferencingRelationship} can be used to compute the outgoing cell fluxes, which serve as the incoming flux values for the next mesh cell. This process is repeated until each cell has been computed. If there are no scattering, fission, or external sources in Eq. \eqref{eq:psi_ijk}, then only one transport sweep is required. However, if these sources are present, then at the end of each sweep, an updated \(S_{ijk}\) must be computed, and the sweep repeated until reaching convergence. 

If reflective boundary conditions are present, then begin from the side of the domain for which the conditions are known, and then upon reaching the reflective boundary, apply the reflective condition, then perform a sweep in the opposite direction (using the other stepping relations developed for \(\mu<0\) instead of \(\mu>0\)). This double sweep is then halted to perform updates to \(S_{ijk}\) and then repeated until reaching convergence. If reflective boundary conditions exist on both ends of the domain, then an initial guess for the incoming fluxes at the starting point must be made, and then each double sweep is again halted to perform updates to \(S_{ijk}\) until reaching convergence. 

The Diamond Difference method can produce negative fluxes, and the onset of negative fluxes is related to the mesh spacing \(\Delta_i\). 

\begin{tcolorbox}[breakable]
The onset of negative fluxes with the Diamond Difference method can be shown by solving the 1-D, no-source form of Eq. \eqref{eq:SimpleTE} and then applying the Diamond Difference differencing scheme.

\begin{equation}
\label{eq:Ex2}
\mu\frac{d\psi}{dx}+\Sigma_t\psi=0
\end{equation}

The analytical solution to this equation is:

\begin{equation}
\frac{d\psi}{\psi}=\frac{-\Sigma_t}{\mu}dx\quad\rightarrow\quad\int_{x_{i-1/2}}^{x_{i+1/2}}\frac{d\psi}{\psi}=\int_{x_{i-1/2}}^{x_{i+1/2}}\frac{-\Sigma_t}{\mu}dx
\end{equation}

Performing the integration:

\begin{equation}
\label{eq:124}
\ln{\left(\frac{\psi_{i+1/2}}{\psi_{i-1/2}}\right)}=\frac{-\Sigma_t}{\mu}\Delta_i\quad\rightarrow\quad\psi_{i+1/2}=\exp{\left(\frac{-\Sigma_t}{\mu}\Delta_i\right)}\psi_{i-1/2}
\end{equation}

Alternatively, the Diamond Difference method can be used to determine how \(\psi_{i+1/2}\) is related (numerically, instead of analytically) to \(\psi_{i-1/2}\). Using \(\alpha=0\) in Eq. \eqref{eq:DifferencingRelationship}:

\begin{equation}
\label{eq:122}
\psi_{ijk}=\frac{1}{2}\left(\psi_{i+1/2}+\psi_{i-1/2}\right)
\end{equation}

The numeric form of Eq. \eqref{eq:Ex2} can be obtained in a manner very similar to that in Eq. \eqref{eq:DiscretizedCartesianTE}:

\begin{equation}
\label{eq:123}
\frac{\mu}{\Delta_i}(\psi_{i+1/2}-\psi_{i-1/2})+\Sigma_{t,ijk}\psi_{ijk}=0
\end{equation}

Inserting Eq. \eqref{eq:122} into Eq. \eqref{eq:123} to eliminate \(\psi_{ijk}\) in order to obtain an expression similar to that in Eq. \eqref{eq:124} in terms of only \(\psi_{i+1/2}\) and \(\psi_{i-1/2}\):

\begin{equation}
\psi_{i+1/2}=\frac{1-\Sigma_{t,ijk}\Delta_i/2\mu}{1+\Sigma_{t,ijk}\Delta_i/2\mu}\psi_{i-1/2}
\end{equation}

From this expression, \(\psi_{i+1/2}\) can be negative if:

\begin{equation}
\Delta_i>\frac{2|\mu|}{\Sigma_{t,ijk}}
\end{equation}

By comparing this numerical expression with the analytic expression in Eq. \eqref{eq:124}, we see that the truncation error in the Diamond Difference method is that the numerical expression on the LHS below is used to approximate the exponential term on the RHS:

\begin{equation}
\label{eq:125}
\frac{1-\Sigma_{t,ijk}\Delta_i/2\mu}{1+\Sigma_{t,ijk}}\approx\exp{\left(\frac{-\Sigma_t}{\mu}\Delta_i\right)}
\end{equation}

To determine the order of the truncation error, the Taylor series of \(e^x=1+x+\mathscr{O}(x^2)\). So, for the exponential on the RHS, the Taylor series is:

\begin{equation}
\text{Taylor series of } \exp{\left(\frac{-\Sigma_t}{\mu}\Delta_i\right)}=1+\frac{-\Sigma_{t,ijk}}{\mu}\Delta_i+\mathscr{\Delta_i}^2
\end{equation}

The term in the numerator of the fraction on the LHS of Eq. \eqref{eq:125} is very similar to the Taylor series above, and hence we can see that the truncation error of the Diamond Difference method in this case is of \(\mathscr{O}(\Sigma_t\Delta_i/2|\mu|)^2\). 

\end{tcolorbox}

\subsubsection{Quadrature}

\subsubsubsection{Level-Symmetric Quadrature}
While there are many options for quadrature sets, the Level-Symmetric quadrature set is the set most often associated with the \(S_N\) method. With this set, there are \(N(N+2)\) angular directions per spatial location (N(N+2)/8 per octant). The Level-Symmetric quadrature set uses the same set of \(N/2\) positive values of direction cosines for each of the components of \(\hO  \). Because this quadrature set is symmetric, no direction gets preferential treatment. Different quadrature sets could be used for different computations where it is expected for streaming to occur preferentially in some directions over others. 

Because of the symmetry constraints, not all of the choices for the quadrature points are independent, and in fact there is only one degree of freedom for each choice of quadrature set. A second constraint given by Eq. \eqref{eq:QuadratureNormalization} then narrows down the options for the quadrature set. With these two constraints, \(S_2\) quadrature is fixed, but for higher orders, there are several options remaining for the quadrature points. 

\subsubsubsection{\(LQ_N\) Quadrature}

With the same symmetry and normalization constraints as the Level-Symmetric quadrature set, the \(LQ_N\) quadrature set imposes the additional requirement that the quadrature set should correctly integrate as many Legendre polynomials as possible. 

\subsubsection{Spatial Discretization}

The \(S_N\) equations provide the framework to discretize the angular flux in angle, but the equations still must be discretized in space. In general, there are two different means to perform spatial discretization - cell balance methods, which preserve conservation of the solution, and finite element methods, which do not necessarily preserve conservation of the solution. In a single mesh cell, cell balance methods will provide a statement that is equivalent to conservation of neutrons, while finite element methods satisfy the governing equation in a weighted-integral sense. For simplicity, all of the spatial discretization schemes discussed here are applied to the simplified transport equation that neglects time dependence and assumes some angular discretization has already been applied to \(\psi\) such that it is independent of angle (in each of these equations):

\begin{equation}
\label{eq:SimpleTE}
\hO  \cdot\nabla\psi(\vv{r},E)+\Sigma_t({\vv{r},E})\psi(\vv{r},E)=S(\vv{r},E)
\end{equation}

where \(S\) represents the scattering, fission, and external sources. There will be one of these equations for each discrete direction in the \(S_N\) method. For all the following discretization schemes, a Cartesian mesh given in Fig. \ref{fig:CartesianDiscretization} is assumed, with \(i\) representing indices in the \(x\)-direction, \(j\) in the \(y\)-direction, and \(k\) in the \(z\)-direction.

\begin{figure}[H]
\centering
\includegraphics[width=0.6\linewidth]{figures/CartesianDiscretization.jpg}
\caption{Cartesian discretization to be used for the cell balance schemes.}
\label{fig:CartesianDiscretization}
\end{figure}

\subsubsubsection{Cell Balance Schemes}

Cell balance schemes point values for the solution \(\psi\) over a discretized spatial mesh. With the definitions in Eq. \eqref{eq:OmegaComponentsCartesian} switched around to be consistent with the Denovo manual, integrating Eq. \eqref{eq:SimpleTE} over the mesh cell shown in Fig. \ref{fig:CartesianDiscretization} gives:

\begin{equation}
\int_{x_{i-1/2}}^{x_{i+1/2}}dx\mu \frac{\partial \psi}{\partial x}+\int_{y_{j-1/2}}^{y_{j+1/2}}dy\eta \frac{\partial \psi}{\partial y}+\int_{z_{k-1/2}}^{z_{k+1/2}}dz\xi \frac{\partial \psi}{\partial z}+\Sigma_{t,ijk}{E}\psi_{ijk}(\vv{r},E)=S_{ijk}(E)
\end{equation}

where it has been assumed that \(\Sigma_t\) and \(S\) are constant over the cell, and are represented by their cell-centered values. In addition, the energy-dependence has been dropped, though the dependency could easily be re-introduced by simply carrying around the \((E, t)\) notation after each occurrence of \(\psi\). Without approximation, the integrals in the above reduce to:

\begin{equation}
\label{eq:DiscretizedCartesianTE}
\frac{\mu}{\Delta_i}(\psi_{i+1/2}-\psi_{i-1/2})+\frac{\eta}{\Delta_j}(\psi_{j+1/2}-\psi_{j-1/2})+\frac{\xi}{\Delta_k}(\psi_{k+1/2}-\psi_{k-1/2})+\Sigma_{t,ijk}\psi_{ijk}=S_{ijk}
\end{equation}

With this discretization method, there must be some way to relate the cell-centered value \(ijk\) to the face values. The different options we have for discretization are related to the choices we can make for how to relate these quantities. The Diamond Difference and Step Difference schemes choose the following relationship:

\begin{equation}
\label{eq:DifferencingRelationship}
\psi_{i\pm1/2}=\frac{2}{1\pm\alpha}\psi_{ijk}-\frac{1\mp\alpha}{1\pm\alpha}\bar{\psi}_{i\mp1/2}
\end{equation}

and likewise for the \(y\) and \(z\) directions. \(\bar{\psi}\) represents a known flux, and depending on whether a sweep is being performed in the positive-\(\mu\) direction (\(\bar{\psi}_{i-1/2}\) is known) or in the negative-\(\mu\) direction (\(\bar{\psi}_{i+1/2}\) is known), either the + or - option is selected in Eq. \eqref{eq:DifferencingRelationship}. The objective is to choose the correct relationship in Eq. \eqref{eq:DifferencingRelationship} such that the known quantities, or the incoming fluxes to each cell, can be used to compute the unknown quantities, or the outgoing fluxes for each cell, in a ``sweep'' over the spatial mesh. For example, for a sweep in the positive-\(\mu\) direction, we supposedly know \(\bar{\psi}_{i-1/2}\), so we would relate the cell-centered flux to the outgoing flux in the following way:

\begin{equation}
\begin{aligned}
\psi_{i+1/2}=\frac{2}{1+\alpha}\psi_{ijk}-\frac{1-\alpha}{1+\alpha}\bar{\psi}_{i-1/2}\quad\quad\mu >0\\
\psi_{ijk}=\frac{1}{2}\left\lbrack(1+\alpha)\psi_{i+1/2}+(1-\alpha)\bar{\psi}_{i-1/2}\right\rbrack\\
\end{aligned}
\end{equation}

Likewise, for a sweep in the negative-\(\mu\) direction, we supposedly know \(\bar{\psi}_{i+1/2}\), so we would relate the cell-centered flux to the outgoing flux in the following way:

\begin{equation}
\begin{aligned}
\psi_{i-1/2}=\frac{2}{1-\alpha}\psi_{ijk}-\frac{1+\alpha}{1-\alpha}\bar{\psi}_{i+1/2}\quad\quad\mu <0\\
\psi_{ijk}=\frac{1}{2}\left\lbrack(1+\alpha)\psi_{i+1/2}+(1-\alpha)\bar{\psi}_{i-1/2}\right\rbrack\\
\end{aligned}
\end{equation}

Note that both of these provide equivalent expressions, but the choice depends on the sweep direction. The differencing scheme in Eq. \eqref{eq:DifferencingRelationship} is a Crank-Nicolson method in space. Inserting Eq. \eqref{eq:DifferencingRelationship} into the discretized transport equation in Eq. \eqref{eq:SimpleTE} gives the following equation for the cell-centered flux in terms of known quantities:

\begin{equation}
\label{eq:psi_ijk}
\psi_{ijk}=\frac{S_{ijk}+\frac{2}{1\pm\alpha}\left(\frac{|\mu|}{\Delta_i}\bar{\psi}_{i\mp1/2}+\frac{|\eta|}{\Delta_j}\bar{\psi}_{j\mp1/2}+\frac{|\xi|}{\Delta_k}\bar{\psi}_{k\mp1/2}\right)}{\Sigma_{t,ijk}+\frac{2}{1\pm\alpha}\left(\frac{|\mu|}{\Delta_i}+\frac{|\eta|}{\Delta_j}+\frac{|\xi|}{\Delta_k}\right)}
\end{equation}

where it has been assumed that \(\alpha\) is selected to be the same in all directions. \(\alpha\) is a parameter used to tune the spatial discretization. Common choices for \(\alpha\) have their own names. The Diamond Difference method sets \(\alpha=0\). With this choice, the cell-centered flux is an average of the face fluxes. The Step Difference method, on the other hand, sets \(\alpha=\pm1\) such that the cell-centered flux is set equal to the incoming face flux (choose 1 or -1 accordingly so that Eq. \eqref{eq:DifferencingRelationship} provides an expression for \(\psi_{ijk}\) in terms of the known incoming face flux).The Diamond Difference method is second-order in space, while the Step Difference method is only first-order. 

In a ``transport sweep,'' computation begins at a boundary for which the boundary condition is known. At this boundary, the incoming fluxes are known. Then, Eq. \eqref{eq:psi_ijk} is used to solve for \(\psi_{ijk}\) using the incoming flux values. Once the cell-centered flux is known, Eq. \eqref{eq:DifferencingRelationship} can be used to compute the outgoing cell fluxes, which serve as the incoming flux values for the next mesh cell. This process is repeated until each cell has been computed. If there are no scattering, fission, or external sources in Eq. \eqref{eq:psi_ijk}, then only one transport sweep is required. However, if these sources are present, then at the end of each sweep, an updated \(S_{ijk}\) must be computed, and the sweep repeated until reaching convergence. 

If reflective boundary conditions are present, then begin from the side of the domain for which the conditions are known, and then upon reaching the reflective boundary, apply the reflective condition, then perform a sweep in the opposite direction (using the other stepping relations developed for \(\mu<0\) instead of \(\mu>0\)). This double sweep is then halted to perform updates to \(S_{ijk}\) and then repeated until reaching convergence. If reflective boundary conditions exist on both ends of the domain, then an initial guess for the incoming fluxes at the starting point must be made, and then each double sweep is again halted to perform updates to \(S_{ijk}\) until reaching convergence. 

The Diamond Difference method can produce negative fluxes, and the onset of negative fluxes is related to the mesh spacing \(\Delta_i\). Some codes have options called ``Negative-Flux-Fixup'' that remedy these negative fluxes in order to still use relatively coarse spatial meshes. In these methods, whenever an outgoing flux is computed to be negative, then the face flux is set to zero, and \(\psi_{ijk}\) recalculated. This is repeated until all outgoing fluxes are positive. Because the corrected solution depends on \(\psi\), this method is nonlinear.  

\begin{tcolorbox}[breakable]
The onset of negative fluxes with the Diamond Difference method can be shown by solving the 1-D, no-source form of Eq. \eqref{eq:SimpleTE} and then applying the Diamond Difference differencing scheme.

\begin{equation}
\label{eq:Ex2}
\mu\frac{d\psi}{dx}+\Sigma_t\psi=0
\end{equation}

The analytical solution to this equation is:

\begin{equation}
\frac{d\psi}{\psi}=\frac{-\Sigma_t}{\mu}dx\quad\rightarrow\quad\int_{x_{i-1/2}}^{x_{i+1/2}}\frac{d\psi}{\psi}=\int_{x_{i-1/2}}^{x_{i+1/2}}\frac{-\Sigma_t}{\mu}dx
\end{equation}

Performing the integration:

\begin{equation}
\label{eq:124}
\ln{\left(\frac{\psi_{i+1/2}}{\psi_{i-1/2}}\right)}=\frac{-\Sigma_t}{\mu}\Delta_i\quad\rightarrow\quad\psi_{i+1/2}=\exp{\left(\frac{-\Sigma_t}{\mu}\Delta_i\right)}\psi_{i-1/2}
\end{equation}

Alternatively, the Diamond Difference method can be used to determine how \(\psi_{i+1/2}\) is related (numerically, instead of analytically) to \(\psi_{i-1/2}\). Using \(\alpha=0\) in Eq. \eqref{eq:DifferencingRelationship}:

\begin{equation}
\label{eq:122}
\psi_{ijk}=\frac{1}{2}\left(\psi_{i+1/2}+\psi_{i-1/2}\right)
\end{equation}

The numeric form of Eq. \eqref{eq:Ex2} can be obtained in a manner very similar to that in Eq. \eqref{eq:DiscretizedCartesianTE}:

\begin{equation}
\label{eq:123}
\frac{\mu}{\Delta_i}(\psi_{i+1/2}-\psi_{i-1/2})+\Sigma_{t,ijk}\psi_{ijk}=0
\end{equation}

Inserting Eq. \eqref{eq:122} into Eq. \eqref{eq:123} to eliminate \(\psi_{ijk}\) in order to obtain an expression similar to that in Eq. \eqref{eq:124} in terms of only \(\psi_{i+1/2}\) and \(\psi_{i-1/2}\):

\begin{equation}
\psi_{i+1/2}=\frac{1-\Sigma_{t,ijk}\Delta_i/2\mu}{1+\Sigma_{t,ijk}\Delta_i/2\mu}\psi_{i-1/2}
\end{equation}

From this expression, \(\psi_{i+1/2}\) can be negative if:

\begin{equation}
\Delta_i>\frac{2|\mu|}{\Sigma_{t,ijk}}
\end{equation}

By comparing this numerical expression with the analytic expression in Eq. \eqref{eq:124}, we see that the truncation error in the Diamond Difference method is that the numerical expression on the LHS below is used to approximate the exponential term on the RHS:

\begin{equation}
\label{eq:125}
\frac{1-\Sigma_{t,ijk}\Delta_i/2\mu}{1+\Sigma_{t,ijk}}\approx\exp{\left(\frac{-\Sigma_t}{\mu}\Delta_i\right)}
\end{equation}

To determine the order of the truncation error, the Taylor series of \(e^x=1+x+\mathscr{O}(x^2)\). So, for the exponential on the RHS, the Taylor series is:

\begin{equation}
\text{Taylor series of } \exp{\left(\frac{-\Sigma_t}{\mu}\Delta_i\right)}=1+\frac{-\Sigma_{t,ijk}}{\mu}\Delta_i+\mathscr{O}(\Delta_i)^2
\end{equation}

The term in the numerator of the fraction on the LHS of Eq. \eqref{eq:125} is very similar to the Taylor series above, and hence we can see that the truncation error of the Diamond Difference method in this case is of \(\mathscr{O}(\Sigma_t\Delta_i/2|\mu|)^2\). 
\end{tcolorbox}

Aside from the Diamond Difference and Step Difference schemes, a third differencing scheme, Theta-Weighted Diamond Difference, chooses two additional weight parameters based on the incoming fluxes. These additional parameters allow the outgoing fluxes to vary smoothly between the Step and Diamond Difference schemes. These weighting parameters are bounded between the Diamond Difference and Step Difference methods. Provided the source is positive, the Theta-Weighted Diamond Difference and Weighted Diamond Difference with Flux-Fixup both give positive fluxes.

\subsubsection{Operator Form}

This section covers the operator form of the transport equation, where the scattering term has been expanded in spherical harmonics as in Eq. \eqref{eq:SnGeneral}, repeated below for convenience:

\begin{equation}
\label{eq:StartofOperatorForm}
\begin{aligned}
 \hO  _a\cdot\nabla\psi_a^g(\vv{r}) + 
 \Sigma_t^g(\vv{r})\psi_a^g(\vv{r}) = \\
\sum_{l=0}^{N}\left\lbrack Y_{l0}^e(\hO  _a)s_{l0}^g(\vv{r})+\sum_{m=1}^{l}\left(Y_{lm}^e(\hO  _a)s_{lm}^g(\vv{r})+Y_{lm}^o(\hO  _a)v_{lm}^g(\vv{r})\right)\right\rbrack+\\
\sum_{g'=1}^G\sum_{l=0}^{N}\Sigma_{s,l}(\vv{r}, g'\rightarrow g)\left\lbrack Y_{l0}^e(\hO  _a)e_{l0}^{g'}(\vv{r})+\sum_{m=1}^{l}\left(Y_{lm}^e(\hO  _a)e_{lm}^{g'}(\vv{r})+Y_{lm}^o(\hO  _a)o_{lm}^{g'}(\vv{r})\right)\right\rbrack\quad\\
\end{aligned}
\end{equation}

where the equation has now been transformed to a form that accounts for energy groups, rather than applying to a within-group equation. So, all energy dependence is removed, since a group structure now accounts for that dependence. The \(g\) superscript refers to the energy group number, and \(G\) to the total number of energy groups. Within-group scattering is counted in the scattering term, but is canceled by the total interaction term, which avoids double counting. The above equation can be cast in operator form. The external group source is defined as:

\begin{equation}
q_e^g(\vv{r})=\sum_{l=0}^{N}\left\lbrack Y_{l0}^e(\hO  _a)s_{l0}^g(\vv{r})+\sum_{m=1}^{l}\left(Y_{lm}^e(\hO  _a)s_{lm}^g(\vv{r})+Y_{lm}^o(\hO  _a)v_{lm}^g(\vv{r})\right)\right\rbrack
\end{equation}

in order to permit easier equation manipulation. In addition, several operators are defined. The transport operator is:

\begin{equation}
\textbf{L}\equiv\hO  _a\cdot\nabla+\Sigma_t^g
\end{equation}

and the solution vector \(\Psi\) is a column vector containing each energy group flux vector \(\vv{\psi}\):

\begin{equation}
\Psi=\begin{bmatrix}\vv{\psi}_1&\vv{\psi}_2&\vv{\psi}_3&\cdots&\vv{\psi}_G\end{bmatrix}^T
\end{equation}

where \(\vv{\psi}\) is then a column vector that contains the flux for each discrete angle for that particular energy group \(g\):

\begin{equation}
\vv{\psi}_g=\begin{bmatrix}\psi_1^g&\psi_2^g&\psi_3^g&\cdots&\psi_n^g\end{bmatrix}^T
\end{equation}

So, the vector of unknowns is organized by energy group, and in the section pertaining to each group, by angle. In order to discuss the size of these matrices and vectors, several variables are defined:

\begin{equation}
\begin{aligned}
G=&\ \text{number of energy groups}\\
t = &\ \text{number of moments}\\
n = &\ \text{number of angles}\\
N = &\ P_N\text{\ order}\\
N_c=&\ \text{number of cells}\\
N_e=&\ \text{number of unknowns per cell}\\
\end{aligned}
\end{equation} 

So, if the problem consisted of a single cell with a single node (i.e. only one spatial unknown), then \(\Psi\) would be an \((Gn)\times1\) vector. However, the problems solves will consist of a spatial domain that is also present in \(\Psi\). In reality, each \(\psi_{\hO  _n}^g\) term is solved as a function of space, and is therefore not a scalar value, but an \(N_cN_e\times1\) vector. The \(S_N\) equation for a particular angle and group is solved as a function of space using a variety of methods, such as the finite element method or the finite difference method. So, the total size of \(\Psi\) is \(N_cN_eGn\times1\). The external source \(q_e^g\) is defined in a similar manner, and is represented as \(Q\), an \(N_cN_eGn\times1\) vector.

Expressing the mapping between flux moments and the scattering term is more difficult simply due to the difficulty in visualizing the matrix multiplication. The moment-to-discrete matrix is used to project harmonic moments onto discrete angle space. It is defined as:

\begin{equation}
\textbf{M}=\left\{
\begin{array}{*{13}c}
Y_{00}^o(\hO  _1) & Y_{00}^e(\hO  _1) & Y_{01}^o(\hO  _1) & Y_{01}^e(\hO  _1) & Y_{10}^o(\hO  _1) & Y_{10}^e(\hO  _1) & Y_{11}^o(\hO  _1) & Y_{11}^e(\hO  _1) & \cdots & Y_{NN}^o(\hO  _1) & Y_{NN}^e(\hO  _1)\\
Y_{00}^o(\hO  _2) & Y_{00}^e(\hO  _2) & Y_{01}^o(\hO  _2) & Y_{01}^e(\hO  _2) & Y_{10}^o(\hO  _2) & Y_{10}^e(\hO  _2) & Y_{11}^o(\hO  _2) & Y_{11}^e(\hO  _2) & \cdots & Y_{NN}^o(\hO  _2) & Y_{NN}^e(\hO  _2)\\
\vdots & \vdots & \vdots & \vdots & \vdots & \vdots & \vdots & \vdots & \vdots & \vdots & \vdots \\
Y_{00}^o(\hO  _n) & Y_{00}^e(\hO  _n) & Y_{01}^o(\hO  _n) & Y_{01}^e(\hO  _n) & Y_{10}^o(\hO  _n) & Y_{10}^e(\hO  _n) & Y_{11}^o(\hO  _n) & Y_{11}^e(\hO  _n) & \cdots & Y_{NN}^o(\hO  _n) & Y_{NN}^e(\hO  _n)\\
\end{array}\right\}
\end{equation}

But, some of these components are actually always zero - for instance, from the expansion in Eq. \eqref{eq:StartofOperatorForm}, if \(l=0\), then there are no spherical harmonics for which \(m\neq0\). This eliminates \(Y_{01}^e\) and \(Y_{01}^o\). In addition, \(Y_{00}^o=0\) and \(Y_{10}^o=0\) since there is no odd component for \(l=0,i\) and \(m=0\). This gives a simplified version of the moment-to-discrete matrix, where the only difference between this matrix and the more explicit one above is that several of the low \(l\) and \(m\) spherical harmonics that are zero are removed.

\begin{equation}
\textbf{M}=\left\{
\begin{array}{*{13}c}
Y_{00}^e(\hO  _1)  & Y_{10}^e(\hO  _1) & Y_{11}^o(\hO  _1) & Y_{11}^e(\hO  _1) & Y_{20}^e(\hO  _1) & \cdots & Y_{NN}^o(\hO  _1) & Y_{NN}^e(\hO  _1)\\
Y_{00}^e(\hO  _2)  & Y_{10}^e(\hO  _2) & Y_{11}^o(\hO  _2) & Y_{11}^e(\hO  _2) & Y_{20}^e(\hO  _2) & \cdots & Y_{NN}^o(\hO  _2) & Y_{NN}^e(\hO  _2)\\
\vdots & \vdots & \vdots & \vdots & \vdots & \vdots & \vdots & \vdots \\
Y_{00}^e(\hO  _n) & Y_{10}^e(\hO  _n) & Y_{11}^o(\hO  _n) & Y_{11}^e(\hO  _n) & Y_{20}^e(\hO  _n) & \cdots & Y_{NN}^o(\hO  _n) & Y_{NN}^e(\hO  _n)\\
\end{array}\right\}
\end{equation}

The scattering matrix contains along its diagonal the scattering moments:

\begin{equation}
\textbf{S}_{g^{'}\rightarrow g}=\begin{bmatrix}
\Sigma_{s0}
\end{bmatrix}
\end{equation}

With this definition, the discretization of the transport equation leads to the following matrix system:

\begin{equation}
\textbf{L}\begin{bmatrix}\Psi_1\\\Psi_2\\\Psi_3\\\vdots\\\Psi_G\end{bmatrix}=
\begin{bmatrix}
\textbf{M} & 0 & 0 & 0 & 0\\
0 & \textbf{M} & 0 & 0 & 0\\
0 & 0 & \textbf{M} & 0 & 0\\
0 & 0 & 0 & \cdots & 0\\
0 & 0 & 0 & 0 & \textbf{M}\\
\end{bmatrix}
\begin{bmatrix}
\textbf{S}_{11} & \textbf{S}_{12} & \textbf{S}_{13} & \cdots & \textbf{S}_{1G}\\
\textbf{S}_{21} & \textbf{S}_{22} & \textbf{S}_{23} & \cdots & \textbf{S}_{2G}\\
\textbf{S}_{31} & \textbf{S}_{32} & \textbf{S}_{33} & \cdots & \textbf{S}_{3G}\\
\vdots & \vdots & \vdots & \vdots & \vdots\\
\textbf{S}_{G1} & \textbf{S}_{G2} & \textbf{G}_{23} & \cdots & \textbf{S}_{GG}\\
\end{bmatrix}
\begin{bmatrix}
\Phi_1\\\Phi_2\\\Phi_3\\\vdots\\\Phi_G
\end{bmatrix}
+
\begin{bmatrix}
Q_1\\Q_2\\Q_3\\\vdots\\Q_G
\end{bmatrix}
\end{equation}

Hence, the upper triangular portion of the scattering matrix represents upscattering, while the diagonal represents within-group scattering, and the lower triangular portion represents downscattering. \(\Phi\) represents a vector of the angular flux moments used in the expansion of the scattering term, organized by group. 

\begin{equation}
\Phi_g=\begin{bmatrix}
o_{00}^g & e_{00}^g & o_{01}^g & e_{01}^g & o_{10}^g & e_{10}^g & \cdots & o_{NN}^g & e_{NN}^g\\
\end{bmatrix}^T
\end{equation}

where \(e_{lm}\) and \(o_{lm}\) are defined by Eq. \eqref{eq:FluxMoments31}. Note, however, that some of these terms are zero due to how the expansion is performed. Moments with \(l=0\) are only nonzero for \(m=0\). And, there is no odd component for \(l=0\). 

\begin{equation}
\Phi_g=\begin{bmatrix}
e_{00}^g & e_{10}^g & o_{11}^g & e_{11}^g & \cdots & o_{NN}^g & e_{NN}^g\\
\end{bmatrix}^T
\end{equation}

The flux moment vector can be related to the angular flux vector by \(\textbf{D}\):

\clearpage
\input{spectral-angular.tex}

\clearpage
 
\subsubsection{1-D Cartesian Derivation}

Due to the added complexity associated with higher dimensions, the \(P_N\) equations are derived here for the time-independent form of the 1-D, monoenergetic transport equation in Cartesian geometries given by Eq. \eqref{eq:TE_Cartesian_1D_2_noenergy}, repeated here for reference, where the external and fission source are bundled together into \(S\), which is assumed isotropic:

\begin{equation*}
\mu \frac{\partial \psi(z, \mu)}{\partial z} +
 \Sigma_t(z)\psi(z, \mu) =\int_{4\pi}^{} d\hO  ' \Sigma_s(z, \hO  \cdot\hO  ')\psi(z,\hO  ') + \frac{S(z)}{4\pi}
 \end{equation*}

The \(P_N\) approximation is made by expanding both the flux and scattering cross section in Legendre polynomials in a similar fashion to the scattering cross section as shown in Eq. \eqref{eq:ScatteringLegendre}. We use Legendre polynomials here because we're in 1-D Cartesian geometry; in higher dimensions or in non-Cartesian frames, the spherical harmonics would be needed.

\begin{equation}
\label{eq:AngularFluxPN}
\psi(z,\mu)=\sum_{n=0}^{\infty}\frac{2n+1}{4\pi}\phi_n(z)P_n(\mu)
\end{equation}

\begin{equation}
\label{eq:PNScatteringCrossSectionExpansion}
\Sigma_s(z,\hO  \cdot\hO  ')=\sum_{l=0}^{\infty}\frac{2l+1}{4\pi}\Sigma_{sl}(z)P_l(\hO  \cdot\hO  ')\rightarrow\sum_{l=0}^{\infty}\frac{2l+1}{4\pi}\Sigma_{sl}(z)P_l(\mu)P_l(\mu')
\end{equation}

where \(n\) is used in the expansion of the flux to differentiate it from \(l\) used in expanding the scattering cross section. From the 1-D form of the addition theorem for spherical harmonics given in Eq. \eqref{eq:AddSpherical1D}, the scattering cross section expansion has been simplified. Now, inserting Eqs. \eqref{eq:AngularFluxPN} and \eqref{eq:AngularFluxPN} into the 1-D transport equation listed in the beginning of this section:

\begin{equation}
\begin{aligned}
\mu \frac{\partial}{\partial z}\left(\sum_{n=0}^{\infty}\frac{2n+1}{4\pi}\phi_n(z)P_n(\mu)\right) + \Sigma_t(z)\sum_{n=0}^{\infty}\frac{2n+1}{4\pi}\phi_n(z)P_n(\mu) =\quad\quad\\
\int_{4\pi}^{} d\hO  ' \sum_{l=0}^{\infty}\frac{2l+1}{4\pi}\Sigma_{sl}(z)P_l(\mu)P_l(\mu')\sum_{n=0}^{\infty}\frac{2n+1}{4\pi}\phi_n(z)P_n(\mu) + \frac{S(z)}{4\pi}
 \end{aligned}
 \end{equation}

Because no quantities depend on \(\hO  \), the scattering integral can be integrated over \(0\leq\phi\leq2\pi\) so that the integral becomes a function of only \(\mu\) and space.

\begin{equation}
\label{eq:PNStep1}
\begin{aligned}
\mu \frac{\partial}{\partial z}\left(\sum_{n=0}^{\infty}\frac{2n+1}{4\pi}\phi_n(z)P_n(\mu)\right) + \Sigma_t(z)\sum_{n=0}^{\infty}\frac{2n+1}{4\pi}\phi_n(z)P_n(\mu) =\quad\quad\\
2\pi\int_{-1}^{1} d\mu' \sum_{l=0}^{\infty}\frac{2l+1}{4\pi}\Sigma_{sl}(z)P_l(\mu)P_l(\mu')\sum_{n=0}^{\infty}\frac{2n+1}{4\pi}\phi_n(z)P_n(\mu) + \frac{S(z)}{4\pi}
 \end{aligned}
 \end{equation}
 
The orthogonality property of Legendre polynomials given in Eq. \eqref{eqn:LegendrePolynomialsOrthogonality} does not permit any extra terms (that depend on \(\mu\)) to be present in the integrand. Hence, the first term in Eq. \eqref{eq:PNStep1} must be rewritten using the recursive property of Legendre polynomials given in Eq. \eqref{eqn:LegendrePolynomialRecursion1}:

 \begin{equation}
\label{eq:PNStep2}
\begin{aligned}
\frac{\partial}{\partial z}\left(\sum_{n=0}^{\infty}\frac{\cancel{2n+1}}{4\pi}\phi_n(z)\frac{1}{\cancel{2n+1}} \left\lbrack(n+1)P_{n+1}(\mu) + n P_{n-1}(\mu)\right\rbrack\right) + \Sigma_t(z)\sum_{n=0}^{\infty}\frac{2n+1}{4\pi}\phi_n(z)P_n(\mu) =\quad\quad\\
2\pi\int_{-1}^{1} d\mu' \sum_{l=0}^{\infty}\frac{2l+1}{4\pi}\Sigma_{sl}(z)P_l(\mu)P_l(\mu')\sum_{n=0}^{\infty}\frac{2n+1}{4\pi}\phi_n(z)P_n(\mu) + \frac{S(z)}{4\pi}
 \end{aligned}
 \end{equation}
 
 Multiplying Eq. \eqref{eq:PNStep2} by \(P_n(\mu)\) and then integrating over \(-1\leq\mu\leq1\) gives, after canceling the \(1/4\pi\) from each term:
 
  \begin{equation}
\label{eq:PNStep3}
\begin{aligned}
\frac{\partial}{\partial z}\left(\sum_{n=0}^{\infty}\left\lbrack\int_{-1}^{1}d\mu\phi_n(z)(n+1)P_{n+1}(\mu)P_n(\mu) + \int_{-1}^{1}d\mu\phi_n(z)n P_{n-1}(\mu)P_n(\mu)\right\rbrack\right) + \quad\quad\\
\Sigma_t(z)\sum_{n=0}^{\infty}(2n+1)\int_{-1}^{1}d\mu\phi_n(z)P_n(\mu)P_n(\mu) =\quad\quad\\
\int_{-1}^{1}d\mu P_n(\mu)2\pi\int_{-1}^{1} d\mu' \sum_{l=0}^{\infty}\frac{2l+1}{4\pi}\Sigma_{sl}(z)P_l(\mu)P_l(\mu')\sum_{n=0}^{\infty}(2n+1)\phi_n(z)P_n(\mu)P_n(\mu) + \int_{-1}^{1}d\mu S(z)P_n(\mu)
 \end{aligned}
 \end{equation}

Then, applying the orthogonality property of Legendre polynomials from Eq. \eqref{eqn:LegendrePolynomialsOrthogonality} gives:

  \begin{equation}
\label{eq:PNStep4}
\begin{aligned}
\frac{\partial}{\partial z}\left(\sum_{n=0}^{\infty}\left\lbrack\frac{2(n+1)}{2n+1}\phi_{n+1}(z) +\frac{2n}{2n+1} \phi_{n-1}(z)\right\rbrack\right) + \Sigma_t(z)\sum_{n=0}^{\infty}2\phi_n(z) =\quad\quad\\
2\sum_{l=0}^{\infty}\Sigma_{sl}(z)\sum_{n=0}^{\infty}\phi_n(z) + \int_{-1}^{1}d\mu S(z)P_n(\mu)
 \end{aligned}
 \end{equation}

where orthogonality was applied twice to the scattering term. Dividing through by 2 then gives the \(P_N\) equations for 1-D Cartesian geometries:

\begin{equation}
\label{eq:PNStep5}
\begin{aligned}
\frac{\partial}{\partial z}\left(\sum_{n=0}^{\infty}\left\lbrack\frac{n+1}{2n+1}\phi_{n+1}(z) +\frac{n}{2n+1} \phi_{n-1}(z)\right\rbrack\right) + \Sigma_t(z)\sum_{n=0}^{\infty}\phi_n(z) =\quad\quad\\
\sum_{l=0}^{\infty}\Sigma_{sl}(z)\sum_{n=0}^{\infty}\phi_n(z) + \delta_{n,even}\frac{1}{2}\int_{-1}^{1}d\mu S(z)P_n(\mu)
 \end{aligned}
 \end{equation}

Because \(S(z)\) is not a function of \(\mu\), then the integral of a Legendre polynomial over its basis will give zero if that Legendre polynomial is an odd function, and will be nonzero otherwise. Hence, the source term is only present for even \(n\), based on the first few Legendre polynomials shown in Eq. \eqref{eqn:LegendrePolynomials_P0P1P2}. Now, in order to make this solution method tractable, the infinite sums have to be truncated at some point. It is also customary to set \(l=n\) such that the above reduce to:

\begin{equation}
\label{eq:PNStep6}
\begin{aligned}
\frac{\partial}{\partial z}\left(\sum_{n=0}^{N}\left\lbrack\frac{n+1}{2n+1}\phi_{n+1}(z) +\frac{n}{2n+1} \phi_{n-1}(z)\right\rbrack\right) + \Sigma_t(z)\sum_{n=0}^{N}\phi_n(z) =\quad\quad\\
\sum_{n=0}^{N}\Sigma_{sn}(z)\phi_n(z) +  \delta_{n,even}\frac{1}{2}\int_{-1}^{1}d\mu S(z)P_n(\mu)
 \end{aligned}
 \end{equation}

We can require Eq. \eqref{eq:PNStep6} to hold for all \(N\) at once, but we can also require it to hold for each \(N\). This stricter requirement returns the requirement stated in Eq. \eqref{eq:PNStep6}, and hence the \(P_N\) equations in practice produce \(N\) coupled ODEs:

\begin{equation}
\label{eq:PNEquations}
\begin{aligned}
\frac{\partial}{\partial z}\left\lbrack\frac{n+1}{2n+1}\phi_{n+1}(z) +\frac{n}{2n+1} \phi_{n-1}(z)\right\rbrack + \Sigma_t(z)\phi_n(z) =
\Sigma_{sn}(z)\phi_n(z) +  \delta_{n,even}\frac{1}{2}\int_{-1}^{1}d\mu S(z)P_n(\mu)
 \end{aligned}
 \end{equation}

This gives \(N+1\) coupled equations. For example, some of the first \(P_N\) equations are:
 
 \begin{equation}
 \begin{aligned}
\frac{\partial\phi_{1}(z)}{\partial z} + \Sigma_t(z)\phi_0(z)=\Sigma_{s0}\phi_0(z)+ S_0(z)\quad\quad n=0\\
\frac{2}{3}\frac{\partial\phi_{2}(z)}{\partial z}+\frac{1}{3}\frac{\partial\phi_{0}(z)}{\partial z} + \Sigma_t(z)\phi_1(z)=\Sigma_{s1}\phi_1(z)\quad\quad n=1\\
\frac{3}{5}\frac{\partial\phi_{3}(z)}{\partial z}+\frac{2}{5}\frac{\partial\phi_{1}(z)}{\partial z} + \Sigma_t(z)\phi_2(z)=\Sigma_{s2}\phi_2(z)+ S_2(z)\quad\quad n=2\\
\end{aligned}
\end{equation}

In order to truncate the infinite series to \(N\) unknowns, \(\phi_{-1}=0\) is often set, and either \(\phi_{N+1}=0\) or \(\partial\phi_{N+1}/\partial z=0\) is set as the other condition, where both give equivalent results. \(N\) is usually selected to be odd. If \(N\) were even, then artificial symmetry would be introduced into the problem through application of boundary conditions. In addition, for even \(N\), you do not obtain any additional information (non-linearly independent) from the \(P_N\) equations. 

\subsubsubsection{Boundary Conditions}
Marshak boundary conditions require continuity in the odd flux moments at boundaries. 

\begin{equation}
2\pi\int_{\hO  \cdot\hat{n}<0}^{}d\mu P_l(\mu)\psi(\mu)=2\mu\int_{\hO  \cdot\hat{n}<0}^{}d\mu P_l(\mu)\psi_b(\mu)\quad\quad l=1, 3, 5\cdots N
\end{equation}

where \(\psi_b(\mu)\) is the incoming flux. Expanding flux according to Eq. \eqref{eq:AngularFluxPN} gives:

\begin{equation}
2\pi\int_{\hO  \cdot\hat{n}<0}^{}d\mu P_l(\mu)\sum_{n=0}^{\infty}\frac{2n+1}{4\pi}\phi_n(z)P_n(\mu)=2\mu\int_{\hO  \cdot\hat{n}<0}^{}d\mu P_l(\mu)\psi_b(\mu)\quad\quad l=1, 3, 5\cdots N
\end{equation}

This gives \((N+1)/2\) boundary conditions. For an isotropic boundary:

\begin{equation}
\psi_b(\mu)=\frac{\phi_b}{4\pi}
\end{equation}

For a reflecting boundary, the net current at that boundary is zero. From the form of Eq. \eqref{eq:ScatteringMomentsLegendre}, it can be seen that the flux moments are given by:

\begin{equation}
\phi_l(z)=2\pi\int_{-1}^{1}d\mu\psi(\mu)P_l(\mu)
\end{equation}

For \(l=1\), we see that \(\phi_1\) represents the current. Hence, reflecting boundary conditions extend this argument to require that on vacuum boundaries:

\begin{equation}
\phi_l=0\quad\quad l=1, 3, 5, \cdots, N
\end{equation}

\subsection{Simplified Spherical Harmonics \(SP_N\)}
\label{sec:SPN}

The \(SP_N\), or Simplified \(P_N\), method was developed by Ely Gelbard in the early 1960s as an extension of the 1-D Cartesian \(P_N\) equations to higher dimensions. The \(SP_N\) method represents a``middle-ground'' between the full transport equation and diffusion theory. Gelbard ``derived'' the \(SP_N\) equations by extending the 1-D \(P_N\) equations to 3-D, with relatively little mathematical basis. The \(SP_N\) equations are equivalent to the \(P_N\) equations in slab geometries and in other limited cases, and it is only the relatively good numerical results that justified the use of the method initially, since it was not derived in a particularly rigorous manner. It was not until the 1990s that several mathematicians demonstrated that the \(SP_N\) method does have mathematical foundation, and it was shown that the \(SP_N\) equations are an asymptotic approximation to the transport equation. 

The \(SP_N\) method does not always give superior results to diffusion theory, and if the system is not diffusive or not locally 1-D, then the method gives poorer answers than diffusion theory. Away from the asymptotic limit to the transport equation, the \(SP_N\) equations break down. 

However, the \(SP_N\) equations contain more transport physics than the diffusion equation, and hence can be used to capture boundary layers that would be missed by diffusion theory. With the \(P_N\) equations, in the limit of \(N\rightarrow\infty\), the \(P_N\) solutions converge to the true solution, while this is not necessarily the case with the \(SP_N\) equations. Because the \(SP_N\) equations require higher computational cost, the best intermediate choice is to use the \(SP_3\) equations, since these offer much better solutions than the diffusion equation, without exceptionally higher cost.

A heuristic derivation of the \(SP_N\) equations can be performed using simple arguments regarding the form of the 1-D \(P_N\) equations in Eq. \eqref{eq:PNEquations}. The key to deriving the \(SP_N\) equations is to transform Eq. \eqref{eq:PNEquations} such that the derivative in the even-\(n\) equations is replaced by a divergence, while the derivative in the odd-\(n\) equations is replaced by a gradient. The \(SP_N\) equations therefore are:

\begin{equation}
\label{eq:SPNEquations}
\begin{aligned}
\frac{n+1}{2n+1}\nabla\cdot\vv{\phi}_{n+1}(z)+\frac{n}{2n+1}\nabla\cdot\vv{\phi}_{n-1}(z)+ \Sigma_t(z)\phi_n(z)=\Sigma_{sn}\phi_n(z)+ S_n(z)\quad \textrm{even - } n\\
\frac{n+1}{2n+1}\nabla\phi_{n+1}(z)+\frac{n}{2n+1}\nabla\phi_{n-1}(z)+ \Sigma_t(z)\vv{\phi}_n(z)=\Sigma_{sn}\vv{\phi}_n(z)\quad \textrm{odd - } n\\
\end{aligned}
 \end{equation}

This first-order form gives \(N+1\) equations. The \(SP_N\) equations can also be written in second-order form by solving for the odd moments in the odd-\(n\) equations, and then substituting this into the even moment equations. From the odd-\(n\) equation in Eq. \eqref{eq:SPNEquations}, we obtain:

\begin{equation}
\vv{\phi}_n(z)=\frac{1}{\Sigma_t(z)-\Sigma_{sn}(z)}\left(\frac{n+1}{2n+1}\nabla\phi_{n+1}(z)+\frac{n}{2n+1}\nabla\phi_{n-1}(z)\right)
\end{equation}

because \(\phi_{n+1}\) and \(\phi_n-1\) appear in the \(SP_N\) equations, the above can be used to determine the following additional relationships:

\begin{equation}
\begin{aligned}
\vv{\phi}_{n-1}(z)=\frac{1}{\Sigma_t(z)-\Sigma_{s,n-1}(z)}\left(\frac{n}{2n-1}\nabla\phi_{n}(z)+\frac{n-1}{2n-1}\nabla\phi_{n-2}(z)\right)\\
\vv{\phi}_{n+1}(z)=\frac{1}{\Sigma_t(z)-\Sigma_{s,n+1}(z)}\left(\frac{n+2}{2n+3}\nabla\phi_{n+2}(z)+\frac{n+1}{2n+3}\nabla\phi_{n}(z)\right)\\
\end{aligned}
\end{equation}

Inserting these expressions into the first-order form of the \(SP_N\) equations Eq. \eqref{eq:SPNEquations} then gives the second-order form, which holds for even \(n\):

\begin{equation}
\label{eq:SPNEquations}
\begin{aligned}
\frac{n+1}{2n+1}\nabla\cdot\left\lbrack\frac{1}{\Sigma_t(z)-\Sigma_{s,n+1}(z)}\left(\frac{n+2}{2n+3}\nabla\phi_{n+2}(z)+\frac{n+1}{2n+3}\nabla\phi_{n}(z)\right)\right\rbrack+\quad\quad\\
\frac{n}{2n+1}\nabla\cdot\left\lbrack\frac{1}{\Sigma_t(z)-\Sigma_{s,n-1}(z)}\left(\frac{n}{2n-1}\nabla\phi_{n}(z)+\frac{n-1}{2n-1}\nabla\phi_{n-2}(z)\right)\right\rbrack+\quad\quad\\
 (\Sigma_t(z)-\Sigma_{sn})\phi_n(z)= S_n(z)\\
\end{aligned}
 \end{equation}

The second-order form of the \(SP_N\) equations results in the need to solve half as many equations as the first-order form. In addition, the diffusive behavior of the \(SP_N\) equations makes them much more amenable to solution than the hyperbolic \(P_N\) equations. 

\subsubsection{Boundary Conditions}

Heuristic arguments can be used to determine how the 1-D boundary conditions for the \(P_N\) method can be extended to the \(SP_N\) method. All derivatives are transformed according to \(\partial(.)/\partial x\rightarrow\hat{n}\cdot\nabla(.)\). 

\clearpage
\input{diffusion-equation.tex}



\section{Solving the One-Group Diffusion Equation}

\subsection{Cylindrical Geometries}

In spherical coordinates, Eq. \eqref{eq:OneSpeedDiffusion} becomes:

\begin{equation}
\label{eq:OneSpeedDiffusionCylindrical}
\frac{1}{v} \frac{\partial\phi(\vv{r}, t)}{\partial t} +\frac{1}{r}\frac{\partial}{\partial r}\left\lbrack D(\vv{r},t)\frac{\partial\phi(\vv{r},t)}{\partial r}\right\rbrack + (\Sigma_a(\vv{r},t)-\nu\Sigma_f(\vv{r},t))\phi(\vv{r}, t) = S(\vv{r}, t)
\end{equation}

Assuming steady-state, the above reduces to:

\begin{equation}
\label{eq:OneSpeedDiffusionCylindrical2}
\frac{1}{r}\frac{\partial}{\partial r}\left\lbrack D(\vv{r},t)\frac{\partial\phi(\vv{r},t)}{\partial r}\right\rbrack + (\Sigma_a(\vv{r},t)-\nu\Sigma_f(\vv{r},t))\phi(\vv{r}, t) = S(\vv{r}, t)
\end{equation}

Solutions to problems in cylindrical coordinates where the Laplacian \(\nabla\cdot\nabla\) appears can usually be posed in terms of Bessel functions. Bessel functions are solutions to the Sturm-Louiville problem:

\begin{equation}
\label{eq:SturmLouiville}
\frac{1}{r}\frac{\partial}{\partial r}\left(r\frac{\partial\Gamma(r)}{\partial r}\right)+\left(\pm\lambda^2-\frac{\mu^2}{r^2}\right)\Gamma(r)=0
\end{equation}

where \(\Gamma\) is the solution, which has the form:

\begin{equation}
\begin{aligned}
\Gamma(r)=J_{\mu}(\lambda r)+Y_{\mu}(\lambda r)\quad \textrm{ for positive in }\pm\\
\Gamma(r)=I_{\mu}(\lambda r)+K_{\mu}(\lambda r)\quad\textrm{for negative in }\pm\\
\end{aligned}
\end{equation}






\section{Two-Group Diffusion Theory and the Six-Factor Formula}

The full 2-group diffusion equations, with no assumptions made (except those inherent in diffusion theory), are:

\begin{equation}
\label{Group1}
\frac{1}{v_1}\frac{\partial\phi_1}{\partial t}=S_1 + D_1\nabla^2\phi_1-\Sigma_{r1}\phi_1+\Sigma_{s, 2\rightarrow 1}\phi_2+\frac{\chi_1}{k}\left(\nu_1\Sigma_{f1}\phi_1+\nu_2\Sigma_{f2}\phi_2\right)
\end{equation}

\begin{equation}
\label{Group2}
\frac{1}{v_2}\frac{\partial\phi_2}{\partial t}=S_2 + D_2\nabla^2\phi_2-\Sigma_{r2}\phi_2+\Sigma_{s, 1\rightarrow 2}\phi_1+\frac{\chi_2}{k}\left(\nu_1\Sigma_{f1}\phi_1+\nu_2\Sigma_{f2}\phi_2\right)
\end{equation}

where the removal cross section is defined to be the sum of the absorption cross section and the total scattering cross section, which represents the summation over all energy groups (including \(g\)) of scattering to another group. 

\begin{equation}
\label{RemovalCrossSection}
\Sigma_{r,g}=\Sigma_a+\sum_{g'=1}^{G}+\Sigma_{s, g'\rightarrow g}
\end{equation}








\clearpage
\input{kinetics.tex}

\clearpage
\section{Reactor Kinetics}

This section discusses how the time-dependency of the neutron transport equation can be approximated. In general, the neutron transport equation can be solved in time, where some fraction of neutrons are born promptly with essentially no time delay, and some fraction born delayed according to a decay constant associated with a precursor nuclide. Section \ref{sec:Fission} introduced definitions used to describe the prompt and delayed neutrons.

The number density of these precursor nuclides is given as \(C\), where the density refers to the amount of precursor atoms that {\it always} decay by neutron emission. So, \(C\) is really some fraction of the total precursor concentration in order to reflect the fraction that on average undergoes delayed neutron emission. 

Something important to note about the values for \(\beta\) below is how the decay constants for each group are selected. On average, delayed neutrons are born about 12 seconds after fission. 

\begin{table}[h]
\caption{Delayed Neutron Group Characteristics for U-235 (thermal) and Pu-239 (fast)} % title name of the table
\centering % centering table
\begin{tabular}{c |c c |c c} % creating 10 columns
\hline\hline % inserting double-line
 Group & (Thermal) Half-Life (s) & (Thermal) \(\beta_i\) & (Fast) Half-Life (s) & (Fast) \(\beta_i\)
\\ [0.5ex]
\hline % inserts single-line
1 & 55.6 & 0.0002 & 53.75 & 0.0000783\\
2 & 22.0 & 0.0014 & 22.29 & 0.0057680\\
3 & 6.2  & 0.0012 &  5.19 & 0.0004449\\
4 & 2.3  & 0.0026 &  2.09 & 0.0006757\\
5 & 0.6  & 0.0007 & 0.549 & 0.0002122\\
6 & 0.23 & 0.0003 & 0.216 & 0.0000721\\
\hline % inserts single-line
\end{tabular}
\label{tab:PPer}
\end{table}

Neutron ``hold-up'' in a reflector due to scattering interactions (before returning to the core) can be represented by an artificial delayed neutron group, though this is better approximated by using a modified neutron lifetime. Table \ref{tab:PPer} shows values for \(\beta\) as a function of the fissioning nuclide and energy range.



For fast reactors, \(\beta\) will be lower for heterogeneous designs; in homogeneous designs, a greater fraction of the fissions occur from U-238, and U-238 has a higher \(\beta\) than the fissile isotopes (actinides) used in fast reactors. In an LWR, \(\beta\) typically ranges from 0.007137 (more U-238) to 0.005465 (build-in of Pu-239) over a cycle. However, in fast reactors, \(\beta\) often increases over the core life as Pu-239 transmutes to Pu-241. Once averaged over the isotopes in a fast reactor, \(\beta\) is around 0.0036 for heterogeneous designs. For thermal reactors, natural-U fueled reactors (CANDU) have the highest \(\beta\), and are the furthest from criticality accidents. 

As shown in the table, \(\nu\) is also strongly a function of the fissioning nuclide. U-235 has one of the lowest \(\nu\), while the plutonium isotopes are all on the order of \(\nu=3\). As U-238 transmutes to Pu-239, the average \(\nu\) increases, increasing reactivity.

While this section will show approximations using only one neutron energy group, some energy dependence must be taken into account, since the delayed neutrons are born at an average of 0.5 MeV. This energy, in both fast and thermal systems, is substantially different from the average energy at which fission neutrons are born. Delayed neutrons have higher \(p\) and \(P_{NL}^{fast}\), but lower \(\epsilon\). This energy dependence can be roughly taken into account by modifying the kinetics parameters in the following manner:

\beq
\label{eq:ModifiedKineticsParameters_Lambda1}
\lambda_i \rightarrow \lambda_i p_i P_{NL,i}^{fast}
\eeq

\beq
\label{eq:ModifiedKineticsParameters_Beta2}
\beta_i \rightarrow \frac{\beta_i p_i P_{NL,i}^{fast}}{(1-\beta)pP_{NL}^{fast}+\sum_{i=1}^{6}\beta_i p_i P_{NL}^{fast}}
\eeq

Whether or not the effective \(\beta\) is greater than or less than the actual \(\beta\) depends on whether the reactor is in the fast or thermal spectrum. For thermal reactors, the effective \(\beta\) of the delayed neutrons is higher than the actual fraction of neutrons born delayed, since these delayed neutrons represent a fraction greater than \(\beta\) that eventually induce fission (they are closer to the thermal energies necessary for fission). In large LWRs, the effective \(\beta\) is several percent larger than the actual \(\beta\), but in small research reactors can be 20-30\% larger. However, for fast reactors, the effective \(\beta\) is even smaller than the actual \(\beta\), since fission is even less likely at low energies than in thermal systems. 

\begin{comment}
\begin{equation}
\label{eq:SimplestKineticsModel}
N(t)=N_0k_{eff}^{n}
\end{equation}
\end{comment}

The real purpose of reactor kinetics analysis is to assess how a reactor responds to changes in reactivity. Reactivity is the fractional change in the neutron population per generation, expressed as a fraction of the current generation:

\beq
\label{eq:Reactivity}
\rho=\frac{n_ok-n_o}{n_ok}=\frac{k-1}{k}
\eeq

A common misconception is that the ``1'' in the equation above refers to some assumption that \(k_o=1\), but this is not the case - it is simply based on the definition of reactivity based on a previous generation. The remainder of this section will discuss kinetics approximations to the transport equation.

\subsection{No Delayed Neutrons}
The simplest model of reactor kinetics is if every neutron is born promptly. Assuming an infinite medium, there are no spatial derivatives, so the Laplacian term in the diffusion equation goes to zero.

\beq
\label{eq:InfiniteReactorKinetics1}
\frac{1}{v}\frac{d\phi}{dt}=(\nu\Sigma_f-\Sigma_a)\phi
\eeq

For the one-group approximation, \(\epsilon\) and \(p\) equal 1, so \(k_\infty=\eta f\).

\beq
\label{eq:InfiniteReactorKinetics2}
\frac{1}{v}\frac{d\phi}{dt}=\nu\Sigma_a(k_\infty-1)\phi
\eeq

The infinite medium mean prompt neutron lifetime is defined to be the ratio of the rate at which the neutron population changes \(n(t)\) to the rate at which it is lost via absorption \(L(t)\), since in this infinite medium, absorption is the only way that a neutron's lifetime ends. 

\beq
\label{eq:InfinitePromptLifetime}
l_\infty=\frac{n(t)}{L(t)}=\frac{n(t)}{v\Sigma_an(t)}=\frac{1}{v\Sigma_a}
\eeq

Inserting this definition into Eq. \ref{eq:InfiniteReactorKinetics2} gives the solution

\beq
\label{eq:InfiniteReactorKineticsSolution}
\phi(t)=\phi_0\exp\left(\frac{k_\infty-1}{l_\infty}t\right)
\eeq

This accuracy of this analysis can be enhanced by introducing a modified lifetime to account for both prompt and delayed neutrons by summing the original lifetime of a prompt neutron and the mean lifetime of the remaining six precursor groups. This modified lifetime \(<l>\) should give reasonably accurate results for small reactivity changes. 

\beq
\label{eq:AdjustedLifetime}
\textless l_\infty\textgreater=(1-\beta)l_\infty+\sum_{i=1}^{6} \beta_i\left(l_\infty+\frac{1}{\lambda_i}\right)
\eeq

\begin{comment}
, and because \(P_{NL}\) represents the probability that a neutron \textit{won't} leak from a reactor, we can substitute \(P_{NL}\) in for \(n(t)\) in Eq. \ref{eq:InfinitePromptLifetime}.

\beq
\label{eq:FinitePromptLifetime}
l=\frac{n(t)}{L(t)}=\frac{n(t)}\frac{P_{NL}}{v\Sigma_an(t)}
\eeq
\end{comment}

For a finite medium, neutrons can be lost due to both leakage and absorption, and a similar mean neutron lifetime can be defined, \(l\). \(l\) is on the order of \(10^{-4}\) seconds for thermal reactors, and \(10^{-7}\) for fast reactors, since neutrons in fast systems do not need to spend as much time slowing down as thermal neutrons before they fission. \(l\) is basically a measure of the birth-to-death time.

\subsection{Point Kinetics Equations}
The kinetics equations are derived from diffusion theory. Delayed neutron precursors are produced as a result of fission, and are lost due to decay. Each delayed neutron precursor group is characterized by a decay constant \(\lambda_i\) and the fraction of total delayed neutrons \(\beta_i\) that are born from that precursor group.

\beq
\label{eq:PrecursorEquationKinetics}
\frac{\partial C_i}{\partial t}=-\lambda_i C_i + \beta_i \nu\Sigma_f\phi
\eeq

where \(i\) refers to each group of precursors. In the diffusion equation, the source term in the diffusion equation is modified to account for prompt and delayed neutrons separately.

\beq
\label{eq:NeutronEquationKinetics}
\frac{1}{v}\frac{\partial\phi}{\partial t}=D\nabla^2\phi + (1-\beta)\nu\Sigma_f\phi + \sum_{n=1}^{6} \lambda_i C_i -\Sigma_a\phi
\eeq

So far, Eqs. \ref{eq:PrecursorEquationKinetics} and \ref{eq:NeutronEquationKinetics} are exact (within the limitations of 1-group diffusion theory). The main assumption of the point kinetics approximation is that the flux and precursor densities are separable in space and time, and that they both have the same spatial distribution. It will be convenient to assume that the spatial distribution is given as the fundamental mode spatial eigenfunction, \(\psi_1(\vv{r})\), such that \(C_i(\vv{r},t) = C_i(t)\psi_1(\vv{r})\) and \(\phi(\vv{r},x)=vn(t)\psi_1(\vv{r})\). Inserting these assumptions into Eq. \ref{eq:PrecursorEquationKinetics}, and then canceling the shape function from each term:

\beq
\label{eq:PrecursorEquationKinetics_Separable1}
\frac{dC_i(t)}{dt}=-\lambda_i C_i(t) + \beta_i \nu\Sigma_f vn(t)
\eeq

Substituting the same spatial approximation into Eq. \ref{eq:NeutronEquationKinetics}:

\beq
\label{eq:NeutronEquationKinetics_Separable1}
\psi_1(\vv{r})\frac{\partial n(t)}{\partial t}=vn(t)D\nabla^2\psi_1(\vv{r}) + (1-\beta)\nu\Sigma_fvn(t)\psi_1(\vv{r}) + \sum_{n=1}^{6} \lambda_i C_i(t)\psi_1(\vv{r}) -\Sigma_avn(t)\psi_1(\vv{r})
\eeq

To fully eliminate \(\psi_1(\vv{r})\) from the second equation, we make the approximation that:

\beq
\label{eq:FundamentalModeAssumption}
\nabla^2\psi_1+B_{1}^{2}\psi_1=0
\eeq

where \(B_1\) is the geometric buckling from time-dependent analysis of neutron diffusion. We can make this assumption because Eq. \ref{eq:FundamentalModeAssumption} represents the fundamental mode solution to the diffusion equation (since we could plug in any eigenfunction to the diffusion equation instead of \(\phi\) and still satisfy the equation, since the fundamental mode solution is characterized by the first eigenvalue (\(B_1\)) and the first eigenfunction (\(\psi_1\)). Note that \(\psi_1\) is not the fundamental mode of the unperturbed reactor, but rather of the reactor that has been pushed away from critical. This assumption is therefore only valid for systems not perturbed {\it far} from criticality, since then the eigenvalue problem would not be valid. Making this substitution in Eq. \ref{eq:NeutronEquationKinetics_Separable1} allows cancellation of \(\psi_1\).

\beqa
\label{eq:NeutronEquationKinetics_Separable2}
\frac{\partial n(t)}{\partial t}=&-vn(t)DB_1^2 + (1-\beta)\nu\Sigma_fvn(t) + \sum_{n=1}^{6} \lambda_i C_i(t) -\Sigma_avn(t)\\
=&\ vn(t)\left(-DB_1^2 + (1-\beta)\nu\Sigma_f-\Sigma_a\right) + \sum_{n=1}^{6} \lambda_i C_i(t)\\
\eeqa

Eqs. \ref{eq:PrecursorEquationKinetics_Separable1} and \ref{eq:NeutronEquationKinetics_Separable2} are the point kinetics equations, though they may appear to have a different form from the final appearance that appears in most texts because we have yet to substitute in the definitions for \(l\) from Eq. \ref{eq:FinitePromptLifetime} and \(k=\eta fP_{NL}\), or the 1-group six factor formula. \(\epsilon = 1\) because there is only one group (no fast fission), and \(p=1\) as well because all neutrons reach thermal energies because they are all (supposedly) born thermal. Substituting these assumptions into Eqs. \ref{eq:PrecursorEquationKinetics_Separable1} and \ref{eq:NeutronEquationKinetics_Separable2} gives, after some rearranging, the point-kinetics equations. Several versions of the neutron equation are given to reflect the additional inclusion of the definition of reactivity. In addition, many texts replace \(n\) by \(P\), the power, since the neutron flux is directly related to the power. With this conversion, note that the meaning of \(C\) changes, as it must be normalized in the same way that the neutron density is to obtain consistent units. Replacement of neutron density by power neglects any delay in power generation due to prompt energy and delayed energy (decay of fission products, activation, etc.). 

\begin{equation}
\label{eq:PointKineticsPrecursor3}
\frac{dC_i(t)}{dt}=-\lambda_iC_i(t)+\frac{\beta_i}{\Lambda}n(t)
\end{equation} 

\begin{equation}
\label{eq:PointKineticsNeutrons3}
\begin{aligned}
\frac{dn(t)}{dt}=\left(\frac{k(1-\beta)-1}{l}\right)n(t)+\sum_{i=1}^{6}\lambda_i C_i(t)\\
\frac{dn(t)}{dt}=\left(\frac{\rho(t)-\beta}{\Lambda}\right)n(t)+\sum_{i=1}^{6}\lambda_iC_i(t)\\
\end{aligned}
\end{equation} 

\(B_{1}^{2}\) is taken to equal the geometric buckling, since this is inherently the definition of geometric buckling (the fundamental eigenvalue). The mean neutron generation time \(\Lambda\) is defined to be the ratio of the mean generation time between birth of neutrons from one cycle and the death of the those neutrons in the next cycle. This quantity basically reflects birth-to-birth time. Due to the similarity of interpretation between \(l\) from Eq. \ref{eq:FinitePromptLifetime} and \(\Lambda\), they are often both loosely referred to as the neutron lifetime, though they have different interpretations. If the power is increasing, then the birth-to-death time is longer than the birth-to-birth time, and vice versa. 

\begin{equation}
\label{eq:MeanNeutronGenerationTime}
\Lambda=\frac{l}{k}=\frac{1}{v\nu\Sigma_f}
\end{equation} 

The assumptions made in the derivation of the point kinetics equations in Eqs. \ref{eq:PointKineticsPrecursor3} and \ref{eq:PointKineticsNeutrons3} are important to acknowledge, since when they are violated, a kinetics analysis should involve a brute-force solution to the multigroup equations. We assumed a spatially constant shape function \(\psi_1\), which is obviously invalid for control rod movements, since these strong absorbers have high local impact on flux. In addition, we assumed that there is a single neutron group - this is a huge simplification, and if we were to expand the point kinetics equation to multigroup equations, we would likely need to assume different shape functions for each group, especially in thermal reactors where alternating fuel and moderator lead to the thermal flux being highest in the water, and the fast flux being highest in the fuel. 

The point kinetics equations do not neglect and spatial dependence - rather, they collapse all the spatial dependence by assuming it is time-independent and described by the fundamental eigenfunction such that it cancels from each term. This is more valid for fast reactors, whose large mfp causes spatial effects to be less severe (less hot spots) than in LWRs, where local moderation is essential in determining the local flux. The tighter neutronic coupling for fast reactors means that it is more nearly separable in space and time, which is a necessary assumption of the point kinetics equations. 

The \(\rho(t)\) in Eq. \ref{eq:PointKineticsNeutrons3} is only a function of time - so, while the point kinetics equations normally employed in codes are one-dimensional (time), the reactivity feedback effects often cannot be simplified in such a gross manner, and we need to consider temperature gradients, fuel motion, and other reactivity feedback effects as a function of space. 

Now, several approximations to the point kinetics equations can be made to offer analytical solutions.


\subsection{One Delayed Neutron Group}
If we assume one delayed neutron group, then the summation terms in Eqs. \ref{eq:PointKineticsPrecursor3} and \ref{eq:PointKineticsNeutrons3} become simpler and reduce to a single term, yielding:

\beq
\label{eq:PointKineticsPrecursor_OneDelayedGroup}
\frac{\partial C(t)}{\partial t}=\frac{\beta}{\Lambda}n(t)-\lambda C(t)
\eeq

\beq
\label{eq:PointKineticsNeutrons_OneDelayedGroup}
\frac{\partial n(t)}{\partial t}=\left\lbrack\frac{\rho(t)-\beta}{\Lambda}\right\rbrack n(t)+\lambda C(t)
\eeq

where \(\lambda\) represents a decay constant that is weighted by all of the precursor groups:

\beq
\label{eq:Lambda_OneGroup}
\lambda=\left(\frac{1}{\beta}\sum_{i=1}^{6}\frac{\beta_i}{\lambda_i}\right)^{-1}
\eeq

and \(\beta\) is now the sum of all of the \(\beta_i\) for each precursor group:

\beq
\beta=\sum_{i}\beta_i
\eeq

To solve Eqs. \ref{eq:PointKineticsPrecursor_OneDelayedGroup} and \ref{eq:PointKineticsNeutrons_OneDelayedGroup}, we need two initial conditions. These initial conditions can be obtained by assuming that at \(t=0\) the reactor was at steady state such that the time derivatives are zero:

\beqa
\label{eq:PKE_OneGroup_ICs}
n(t=0)=&\ n_0\\
C(t=0)=&\frac{\beta}{\lambda\Lambda}n_0\\
\eeqa

This system of equations can be solved by seeking exponential solutions of the form \(n=n\exp(\omega t)\) and \(C=C\exp(\omega t)\). Note that this essentially implies that the frequency of the neutron population and the precursor population are the same, which is as expected with a single delayed neutron group. Inserting these forms into Eqs. \ref{eq:PointKineticsPrecursor_OneDelayedGroup} and \ref{eq:PointKineticsNeutrons_OneDelayedGroup} and canceling the exponential terms, we obtain:

\beqa
\label{eq:PKE_OneGroup_AssumedForm}
C\omega=&-\lambda C+\frac{\beta}{\Lambda}n\\
n\omega=&\lambda C+\left(\frac{\rho(t)-\beta}{\Lambda}\right)n\\
\eeqa

Substituting \(C\) from the first equation into the second gives two solutions for \(\omega\):  

\beq
\label{eq:PKEomega}
\omega=\frac{-(\Lambda\lambda+\beta-\rho)\pm\sqrt{(\Lambda\lambda+\beta-\rho)^2+4\Lambda\lambda\rho}}{2\Lambda}
\eeq

Hence, because we have two solutions for \(\omega\), our solutions are of the form:

\beqa
\label{eq:PKE_Solutions_OneGroup}
n(t)=&n_1\exp{\omega_1 t}+n_2\exp{\omega_2 t}\\
C(t)=&C_1\exp{\omega_1 t}+C_2\exp{\omega_2 t}\\
\eeqa 

Using our two initial conditions from Eq. \ref{eq:PKE_OneGroup_ICs} and by plugging in the solutions into the original differential equations (to obtain two time-dependent conditions) in Eqs. \ref{eq:PointKineticsPrecursor_OneDelayedGroup} and \ref{eq:PointKineticsNeutrons_OneDelayedGroup} will provide four equations and four unknowns (\(P_1, P_2, C_1, C_2\)). The solution for neutron population then becomes:

\beq
\label{eq:PowerPKE}
n(t)=n_0\left(\frac{\omega_1+\lambda}{\lambda}\frac{\omega_2}{\omega_2-\omega_1}\exp{\omega_1 t} + \frac{\omega_2+\lambda}{\lambda}\frac{\omega_1}{\omega_1-\omega_2}\exp{\omega_2 t}\right)
\eeq

The two-term exponential behavior will give two different time behaviors, where the \(\omega_1\) term represents the prompt power jump that occurs due to a near-immediate change in the prompt neutron population. The \(\omega_2\) term, which will necessarily result in a slower time response since \(\omega_2<\omega_1\), represents the neutron population changes due to changes in the delayed neutron population. The time behavior is often quoted in terms of a ``period,'' which is the inverse of the coefficient on time in the exponential terms. A period represents the time it takes for the reactor power to increase by a factor of \(e\).

In the limit that \((\Lambda\lambda+\beta-\rho)^2 \gg 4\Lambda\lambda\rho\) and \(\abs{\rho}\ll\beta\) (i.e. a small reactivity insertion), the roots become:

\beqa
\label{eq:omegaPKE2}
\omega_1=&\frac{\lambda\rho}{\beta-\rho}\\
\omega_2=&-\frac{\beta-\rho}{\Lambda}\\
\eeqa 

which when inserted into Eq. \ref{eq:PowerPKE} gives an approximate form for \(P(t)\).

\begin{equation}
\label{eq:PowerPKE2}
P(t)=P_0\left(\frac{\beta}{\beta-\rho}\exp{\left(\frac{\lambda\rho}{\beta-\rho} t\right)} - \frac{\rho}{\beta-\rho}\exp{\left(-\frac{\beta-\rho}{\Lambda} t\right)}\right)
\end{equation} 

Note that with this approximation, the period is undefined for exactly \(\rho_0=\beta\). For reactivity insertions of magnitude less than \(\beta\), the period is always dictated by the first term in Eq. \ref{eq:PowerPKE2}, since the second exponential term dies out quickly. However, for insertions of magnitude greater than \(\beta\), the period is dictated by the second term in Eq. \ref{eq:PowerPKE2}, since the first exponential term dies out quickly. For reactivity insertions of less than \$0.90, the period is unaffected by \(l\), since only the second exponential term includes \(\Lambda\), and hence thermal and fast reactors would behave approximately the same.

\subsection{The Prompt Jump Approximation}

Because the initial response to small reactivity changes, less that \$0.90, is dominated by the prompt neutron lifetime, while longer-term response is governed by the delayed neutron lifetime (for systems below prompt critical), we can make the assumption that the power change is sufficiently slow compared to the other two terms in Eq. \ref{eq:PointKineticsNeutrons3} that we can neglect \(dP/dt\). Then, Eq. \ref{eq:PointKineticsNeutrons3} reduces to:

\begin{equation}
\label{eq:PromptJump1}
0=\left(\frac{\rho(t)-\beta}{\Lambda}\right)n(t)+\sum_{i=1}^{6}\lambda_iC_i(t)
\end{equation} 

Before the reactivity change, the precursor concentration is assumed to be in steady state, so if we applied Eq. \ref{eq:PromptJump1} at two points in time, one immediately before and one immediately after, a reactivity change, then we would be able to state that \(C_i(t)\) is independent if time, such that it could be used to set the results of applying Eq. \ref{eq:PromptJump1} at two points in time \textit{equal} to each other. This gives the prompt jump approximation.

\begin{equation}
\label{eq:PromptJump2}
\frac{P_2}{P_1}\approx\frac{\beta-\rho_1}{\beta-\rho_2}
\end{equation} 

This gives the power immediately following the prompt jump. After this jump, you have a smooth, exponential increase/decrease in power governed by the period associated with the first term in Eq. \ref{eq:PowerPKE2}. For a small insertion of 10 pcm, this gives a 1.5\% increase (assuming no stabilizing feedback effects). This approximation is valid to within about 1\% for small reactivity insertions. Given that the shutdown margin (SDM) is the negative reactivity inserted into the reactor with the highest worth control rod fully ejected, Eq. \ref{eq:PromptJump2} becomes:

\begin{equation}
\label{eq:PromptJumpSDM}
\frac{P_2}{P_1}\approx\frac{\beta}{\beta+\rho_{sdm}}
\end{equation} 

So, the SDM is directly related to how quickly the power will drop (instantaneously) following a scram.





\clearpage
\input{reactivity-control.tex}



\section{Reactivity Coefficients and Defects}

Reactivity coefficients are important to the understanding of the inherent safety of a reactor. Below are included some of the most important reactivity coefficients, with representative values given for thermal and fast reactors. Reactivity coefficients are complex, bceause they themselves are functions of both temperature and burnup, as well as the variable to which \(\rho\) is responding. In addition, for reactors with high leakage (such as most fast reactor designs), because there is such a strong gradient in flux at the core periphery, the overall reactivity response is highly sensitive to core geometry.

A reactivity coefficient \(\alpha\) is the partial derivative of the reactivity \(\rho\) with respect to some parameter, such as temperature or power.

\begin{equation}
\label{eq:ReactivityCoef}
\alpha_x = \frac{\partial\rho}{\partial x}
\end{equation}

Overall, the system reactivity is the sum of external effects \(f(t)\), such as control systems, and inherent feedback effects:

\begin{equation}
\label{eq:OverallReactivity}
\delta k(t) = f(t) + \sum_{i}^{}\alpha_i\delta T_i(t)
\end{equation}

In going from zero power to full power, because the reactor heats up, additional excess reactivity in the cold shutdown state is needed to overcome the reduction in reactivity. This needed reactivity is termed a ``defect.'' All reactors must contain some excess reactivity to compensate for the power and temperature reactivity defects. The power defect is the excess reactivity needed in the cold subcritical state to remain critical at full power. Power defects are on the order of 0.1 \(\delta k/k\). 

\begin{equation}
\label{eq:PowerDefect}
\delta\rho_{Power}=\int_{0}^{Full Power} \frac{\partial\rho}{\partial P}dP
\end{equation}

A temperature defect is similarly defined:

\begin{equation}
\label{eq:TemperatureDefect}
\delta\rho_{Temp}=\int_{ambient}^{operating} \frac{\partial\rho}{\partial T}dT
\end{equation}

Temperature defects for a typical SFR are on the order of 1\$.

\textbf{Temperature Coefficient}
A temperature reactivity coefficient can be defined for each individual material in a reactor, since inherently they will be at different temperatures. However, the overall temperature reactivity coefficient is usually taken as the sum of the temperature coefficients of each specific component, where the temperature in a single component is averaged in some way. The representative temperature is usually a flux-weighted temperature. 

\begin{equation}
\label{eq:TotalTempCoef}
\alpha_T = \Sigma \alpha_j = \Sigma \frac{\partial\rho}{\partial T_j}
\end{equation}

Defining a temperature coefficient becomes difficult, however, when the heat generation in different core elements becomes characterized by very different time scales. For instance, in a typical LWR, there is an 8 second delay between heat generation in the fuel and heat transfer to the coolant.

\subsection{Doppler Broadening Coefficient}

The Doppler effect primarily impacts the resonance escape probability \(p\), since this reflects the probability that neutrons reach thermal energies. If we assume that the Doppler coefficient impacts \(k\) only through \(p\), we can utilize the approximation in Eq. \ref{eq:ReactivityCoef_kExpansion} to give:

\begin{equation}
\label{eq:DopplerCoefficient_pExpansion}
\alpha_D \approx \frac{1}{p}\frac{\partial p}{\partial T_{fuel}}
\end{equation}

For oxide fuels, the Doppler coefficient varies almost exactly as:

\begin{equation}
\label{eq:DopplerCoefficient_OxideFuels}
\frac{dk}{dT}=\frac{K_D}{T}
\end{equation}

where \(K_D\) is called the ``Doppler coefficient,'' even though this is, confusingly, the same name that is given simply to \(dk/dT\). \(K_D\) is basically independent of whether or not there is sodium coolant in the core, and is of order -0.006 to -0.008 for various fast reactor designs. Hence, at lower temperatures, the Doppler coefficient becomes more negative, and so test reactors that have the option to operate at lower temperatures may choose to do so to obtain a favorable Doppler coefficient. For a uniform change in fuel temperature, Eq. \ref{eq:DopplerCoefficient_OxideFuels} may be used to calculate the reactivity feedback from:

\begin{equation}
\label{eq:DopplerCoefficient_OxideFuels2}
\rho=\int_{T_1}^{T_2}\frac{dk}{dT}dT=K_D ln\left(\frac{T_2}{T_1}\right)
\end{equation}

Using the correct temperatures in the above equation is crucial to obtaining the correct Doppler coefficient. From experience, the actual reactivity increase is about 10\% higher in magnitude than it would have been if we simply used average temperatures for \(T_2\) and \(T_1\) in Eq. \ref{eq:DopplerCoefficient_OxideFuels2}. 

Conversely, for metal fuels in fast reactors:

\begin{equation}
\label{eq:DopplerCoefficient_Metal}
\alpha_D\propto \frac{1}{T^{3/2}}
\end{equation}

The Doppler coefficient will also change with burnup, but for fast reactors, this direction of this change is difficult to assess due to a number of simultaneous effects: 1) removal of control rods hardens the spectrum, 2) production of fission products, and 3) small decrease in U-238. Whether or not the control rod withdrawal or the fission product production has the larger effect depends on the internal conversion ratio, since this determines how much of the control rods have to be withdrawn (how much excess reactivity you need to keep going). Because the internal conversion ratio depends on the size of the reactor, the Doppler coefficient change with burnup depends on the size of the reactor. 

\subsection{Moderator Temperature Coefficient (MTC)}

\begin{table}[h]
\caption{Typical MTC for Thermal and Fast Spectrum (Changes are of the Magnitude)}
\centering
\begin{tabular}{l c c c c}
\hline\hline
 Spectrum & Coefficient & Changes with BU & Changes with T & Changes with Void Fraction
\\ [0.5ex]
\hline
Thermal (\(UO_2\)) & -10 pcm/F & decreases & increases & increase\\
Thermal (\(PuO_2\)) & small, + &  &  & \\
Fast (large cores) & + &  & & \\
Fast (small cores) & - &  &  & \\
\hline
\end{tabular}
\label{tab:PPer}
\end{table}

Because in BWRs the coolant is primarily at saturated conditions, the MTC is relatively unimportant in normal operation, but has the greatest impact during startup and shutdown processes when there are no voids in the coolant. In normal operation, any power increases are curbed much more by the void coefficient, and hence in BWRs it is acceptable to have a positive MTC. The MTC may become more positive at EOL when there are more control rods withdrawn, as well, since this increases the moderator-to-fuel ratio). The MTC should not be too negative, however, since then if some undesired transient such as loss of FW heating were to occur, then the power increase could be too large to handle safely.

\subsection{Void Coefficient}

\begin{table}[h]
\caption{Typical Void Coefficients for Thermal and Fast Spectrum (Changes are of the Magnitude)}
\centering
\begin{tabular}{l c c c}
\hline\hline
 Spectrum & Coefficient & Changes with BU & Changes with T
\\ [0.5ex]
\hline
Thermal (\(UO_2\)) & -100 pcm/\% void fraction & decreases & increases \\
Fast (oxide-fueled) &  &  & \\
Fast (metal-fueled) &  &  & \\
\hline
\end{tabular}
\label{tab:PPer}
\end{table}

Because water density decreases at faster rates with increasing temperature, the volumetric expansion in voids also increases at a faster rate the higher the temperature, and hence the void coefficient in water systems increases in magnitude with higher temperatures. At higher burnup, less control rods are present in the core (BWRs), so voids are more distributed. If there are many control rods inserted, then to maintain the power rating, several assemblies must generate significant power, leading to local voids that have a greater negative reactivity impact than if the voids were more evenly distributed. 

For thermal reactors, its actually possible to see a net power decrease when a shallow rod is fully withdrawn, since then voids are allowed to form lower in the core. These voids travel upwards to high power regions, introducing negative reactivity that may be enough to offset the positive reactivity associated with removing a control rod. 

The void coefficient in fast reactors is the combination of four competing effects. It should be noted that a MTC is rarely defined for fast reactors - only the void coefficient is considered, and its definition is relaxed to include density changes that don't necessarily lead to boiling. For an increase in void fraction, or a decrease in coolant density:

\begin{center}
\begin{tabular}{l l}
decreased parasitic absorption by Na-23 & positive insertion\\
increased leakage (longer mfp) & negative insertion\\
decreased self shielding (longer mfp) & positive insertion\\
spectrum hardening (lower \(\alpha\) and higher \(\nu\)) & positive insertion\\
\end{tabular}
\end{center}

The decreased parasitic absorption and changes in self shielding are small effects. So really, calculating the overall void coefficient is equivalent to taking the difference between two large contributions. These combine in such a way that the void coefficient may be positive in the center of the core but negative at the periphery, which is why fast reactors sometimes are designed as high-leakage cores. 

The void coefficient contribution due to spectrum hardening must be weighted with the adjoint flux, and so this positive component of the coefficient is not uniform across the core, since a hardened spectrum will be most important where a significant amount of fission occurs. The void coefficient is hence highly space-dependent. Other ways to mitigate a positive void coefficient include:

\begin{itemize}
\item adding a non-voidable moderator such as BeO (keeps the spectrum soft even if you remove sodium)
\item using NaK instead of Na because it is a poorer moderator, so its removal has a smaller impact on the change in moderation (though using NaK would make the Doppler coefficient more positive)
\item use a fuel with a lower \(\nu\) (use as pure of Pu-239 as possible, since the higher Pu isotopes have higher \(\nu\))
\item use U-233 as one of the fissile fuels (lower rate of increase of \(\eta\) with energy than Pu-239 below 1 MeV)
\item use Th-232 as one of the fertile fuels (lower fast fission fraction relative to U-238)
\item use a higher core pressure to limit the density change upon vaporization
\item increase leakage by using a pancake-shaped core (high axial leakage), flatten the power profile to obtain higher flux gradients at the edges, or use a smaller core
\item increase core heterogeneity
\end{itemize}

Most attempts to improve the void coefficient have been to increase leakage. The most promising method is to use a heterogeneous core, which uses rings of blanket assemblies within the core so that there can be some negative leakage component in the center of the core to these blanket assemblies. Using a heterogeneous core can decrease the positive reactivity upon full core voiding from several dollars to less than a dollar. In addition, if sodium loss were to occur from a heterogeneous core, sodium explusion from the dispersed blanket assemblies would likely lag that of the driver fuel, helping the accident progression further. Using a pancake core or a modular core is worse from an economical standpoint than the heterogeneous core. Adding BeO imposes too large of an economic penalty to be seriously considered.

\subsection{Expansion Coefficient}

In fast reactors, axial expansion occurs when the fuel temperature increases, while the structure that supports the core will expand radially if the inlet sodium temperature increases, leading to radial expansion. Both of these effects are substantial, and are included as credits in the design to help achieve an overall negative reactivity coefficient. In thermal reactors, these effects are much smaller, and can often be neglected. 

Axial expansion is the primary way that a negative prompt coefficient is obtained for metal fuels. For metal fuel in particular, the Doppler feedback is fairly small, so the expansion effect dominates. However, for oxide fuels, a lack of structural integrity makes expansion more difficult, so this expansion coefficient is given secondary importance to the Doppler coefficient, which is substantially more negative than for metal fuels.

Other expansion effects include core compaction (slumping) or fuel extrusion from the tops of pins, dispersing on the top of the reactor internal structures. An important distinction between fast and thermal reactors is that fast reactors are not in their most reactive configuration. The fissile mass could always be reduced if a way were found to reduce the coolant volume fraction. In thermal reactors, a balance is struck to optimize the moderator-to-fuel ratio, but this is not the case in fast reactors, so compaction in a fast reactor can very easily lead to a power increase, while compaction in a thermal reactor introduces negative reactivity.

Expansion of Control Rod Drivelines (CRDL) due to an increase in core outlet temperature will cause the drivelines to move inwards, introducing negative reactivity.

\subsection{Boron Coefficient}

The boron coefficient becomes less negative with an increase in boron concentration due to self-shielding of the boron atoms (a higher effective cross section leads to an increase in the self-shielding effect, which decreases overall absorption). Also, as the moderator temperature increases, the magnitude of the coefficient also decreases, since the density of the absorber therefore also decreases. It is for this reason that the boric acid concentration in the primary loop of PWRs is limited to a maximum of about 1100 ppm, because above this, the MTC becomes positive.

\subsection{Pressure Coefficient}

Pressure coefficients in thermal reactors are relatively small because the reactors are operated at high pressure. Pressure coefficients are typically positive, since they increase the moderator-to-fuel ratio, which increases at a faster rate than the decrease in , leading to a net reactivity increase.

\subsection{Fuel Depletion Effects}

Although fuel depletion is important in the sense that safety analysis is usually performed at BOL, mid-cycle, and EOL, because these changes occur so slowly, they can be decoupled from other more rapid reactivity feedback effects. Build up of fission products and fuel depletion leads to a reactivity change of about -\$6 negative over a fast reactor cycle, about \$3 each. 





\clearpage
\input{appendix.tex}

\clearpage
\input{notation.tex}







\section{Notation}

This section lists all the important notation used in this document. Quantities that are defined are referenced to the equation number in which they are first defined. Basic quantities such as mathematical operators are not associated with a specific equation. Quantities with \(i\) subscripts are intended to represent that \(i\) can take on integer values beginning from \(0\), such as for Legendre polynomials.

\subsection{Symbols}

\begin{tabular}{l l l}
\(\delta\) & Kronecker delta \(\doteq 1\) & ---\\
\(E\) & energy \(\doteq MeV\) & ---\\
\(\Sigma\) & macroscopic cross section \(\doteq 1/m\) & ---\\
\(G\) & total number of energy groups \(\doteq 1\) & ---\\
\(\vv{j}\) & angular current \(\doteq 1/cm^2sMeV\textrm{steradian}\) & Eq. \ref{eq:AngularCurrent}\\
\(\eta\) & Cartesian \(y\)-component of \(\hO  \) \(\doteq 1\) & Eq. \ref{eq:OmegaComponentsCartesian}\\
\(L\) & order of scattering anisotropy \(\doteq 1\) & Eq. \ref{eq:LegendrePolynomialDefinitions}\\
\(l\) & order of Legendre polynomial \(\doteq 1\) & Eq. \ref{eq:LegendrePolynomialDefinitions}\\
\(\lambda\) & decay constant \(\doteq 1/s\) & ---\\
\(m\) & associated Legendre polynomial quantity \(\doteq 1\) & Eq. \ref{eq:AssociatedLegendrePolynomialDiffEq}\\
\(n\) & neutron density \(\doteq 1/m^3\) & ---\\
\(\oslash\) & entire phase space \(\doteq m^3sMeV\textrm{steradian}\) & Eq. \ref{eq:PhaseSpaceIntegration}\\
\(P_i\) & Legendre polynomial \(\doteq \textrm{radians}\) & Eq. \ref{eq:LegendrePolynomialDefinitions}\\
\(\phi\spas\) & scalar flux \(\doteq /cm^2sMeV\) & Eq. \ref{eq:ScalarFlux}\\
\(t\) & time \(\doteq s\) & ---\\
\(V\) & volume element \(\doteq m^3\) & ---\\
\(\nu\) & average number of neutrons born from fission \(\doteq 1\) & ---\\
\(\chi\) & yield \(\doteq 1\) & ---\\
\(Y\) & spherical harmonic \(\doteq 1\) & Eq. \ref{eq:SHAdditionTheorem}\\
\(\psi\spa \) & angular flux \(\doteq 1/cm^2sMeV\cdot\textrm{steradian}\) & Eq. \ref{eq:AngularFlux}\\
\(\volume\) & Volume\\

\end{tabular}


\subsection{Subscripts}

\begin{tabular}{l l}
f & fission\\
g & energy group\\
l & Legendre\\
p & prompt neutron\\
s & scattering\\
t & total\\
\end{tabular}

\subsection{Superscripts}
\begin{tabular}{l l}
* & complex conjugate\\
\(\dagger\) & adjoint\\
\end{tabular}

\clearpage
\providecommand*{\phantomsection}{}
\phantomsection
\addcontentsline{toc}{section}{References}
\bibliographystyle{unsrt}
\bibliography{../../projects/pronghorn/doc/manual/manual}

\end{flushleft}


\end{document}
